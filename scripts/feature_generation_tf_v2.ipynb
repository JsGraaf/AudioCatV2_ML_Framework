{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3c7635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "TF: 2.19.0\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorRt: 10.13.2.6\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_VLOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorrt as trt\n",
    "from typing import Sequence, Optional, Tuple\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorRt:\", trt.__version__)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Tensorflow uniform random generator\n",
    "g1 = tf.random.Generator.from_seed(RANDOM_STATE)\n",
    "\n",
    "TARGET = \"rucwar\"\n",
    "MIN_PER_CLASS = 50\n",
    "OUTER_SPLITS = 2\n",
    "INNER_SPLITS = 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "MAX_DURATION = 10 # seconds\n",
    "NEG_POS_RATIO = 3\n",
    "TRAIN_NEG_RATIO = 2\n",
    "VAL_NEG_RATIO = 2\n",
    "FILL_TYPE = \"pad\" # pad | tile\n",
    "N_MELS = 128\n",
    "N_FRAMES = 157\n",
    "FRAME_OVERLAP = int(np.ceil(N_FRAMES * 0.5))\n",
    "\n",
    "SECONDS = 5\n",
    "BYTES_PER_SECOND = SECONDS * SAMPLE_RATE\n",
    "INPUT_SHAPE = (N_MELS, N_FRAMES, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d8718ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate file rows: 0\n",
      "Total Positives: 154\n",
      "Total Negatives: 61815\n",
      "Avg samples per Class: 168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# birdclef sanity checks\n",
    "def sanity_birdlcef(df: pd.DataFrame, target: str):\n",
    "    # File integrity\n",
    "    for r in df.itertuples():\n",
    "        if os.path.isfile(r.path) is not True: # type:ignore\n",
    "            print(f\"[ERROR]: {r.path} is not valid!\")\n",
    "    \n",
    "    # Dupicates\n",
    "    dups = df['path'].duplicated().sum()  # or 'filename'\n",
    "    print(\"Duplicate file rows:\", dups)\n",
    "    \n",
    "    # Count summary\n",
    "    print(f\"Total Positives: {df[df['primary_label'] == target].shape[0]}\")\n",
    "    print(f\"Total Negatives: {df[df['primary_label'] != target].shape[0]}\")\n",
    "    print(f\"Avg samples per Class: {df['primary_label'].value_counts().mean():.0f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Different functions for each dataset\n",
    "def load_birdclef(audio_root, path, target, min_per_class = MIN_PER_CLASS):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    df[\"path\"] = audio_root + \"/\" + df[\"primary_label\"] + \"/\" + df[\"filename\"]\n",
    "    \n",
    "    # Optional: drop rare classes (keeps CV stable)\n",
    "    if min_per_class > 1:\n",
    "        keep_labels = df[\"primary_label\"].value_counts()\n",
    "        keep_labels = keep_labels[keep_labels >= min_per_class].index\n",
    "        df = df[df[\"primary_label\"].isin(keep_labels)].reset_index(drop=True)\n",
    "    \n",
    "    # Perform sanity checks\n",
    "    sanity_birdlcef(df, target)\n",
    "    \n",
    "    # Group based on auther + time te prevent straddeling\n",
    "    df[\"group_key\"] = df[\"author\"] + df[\"time\"]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "os.chdir(\"/home/joris/Thesis/new_attempt\")\n",
    "\n",
    "birdclef_df = load_birdclef(\"datasets/birdclef_2021/train_short_audio\", \"datasets/birdclef_2021/train_metadata.csv\", target=TARGET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00fe4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_nested_cv_splits(\n",
    "    df: pd.DataFrame,\n",
    "    target: str = TARGET,\n",
    "    outer_splits: int = OUTER_SPLITS,\n",
    "    inner_splits: int = INNER_SPLITS,\n",
    "    random_state: int = RANDOM_STATE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build nested CV folds for binary BirdCLEF: target species = 1, others = 0.\n",
    "    Uses StratifiedGroupKFold for both outer and inner splits to avoid leakage across groups.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Binary labels for stratification\n",
    "    y_all = (df[\"primary_label\"] == target).astype(int).values\n",
    "    groups_all = df[\"group_key\"].astype(str).fillna(\"NA\").values\n",
    "    idx_all = np.arange(len(df))\n",
    "\n",
    "    outer_kf = StratifiedGroupKFold(n_splits=outer_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    nested = []\n",
    "    for k, (outer_tr_idx, outer_te_idx) in enumerate(outer_kf.split(idx_all, y=y_all, groups=groups_all), start=1):\n",
    "        # Outer train/val pool and test set\n",
    "        trval_idx = idx_all[outer_tr_idx]\n",
    "        test_idx  = idx_all[outer_te_idx]\n",
    "\n",
    "        y_trval   = y_all[outer_tr_idx]\n",
    "        groups_trval = groups_all[outer_tr_idx]\n",
    "\n",
    "        # Inner CV on the outer train/val pool\n",
    "        inner_kf = StratifiedGroupKFold(n_splits=inner_splits, shuffle=True, random_state=random_state)\n",
    "        inner_folds = []\n",
    "        for j, (inner_tr_rel, inner_va_rel) in enumerate(inner_kf.split(trval_idx, y=y_trval, groups=groups_trval), start=1):\n",
    "            # Map relative indices back to global indices\n",
    "            inner_tr_idx = trval_idx[inner_tr_rel]\n",
    "            inner_va_idx = trval_idx[inner_va_rel]\n",
    "\n",
    "            inner_folds.append({\n",
    "                \"inner_fold\": j,\n",
    "                \"inner_train_idx\": inner_tr_idx,\n",
    "                \"inner_val_idx\":   inner_va_idx,\n",
    "            })\n",
    "\n",
    "        nested.append({\n",
    "            \"outer_fold\": k,\n",
    "            \"outer_train_idx\": trval_idx,\n",
    "            \"outer_test_idx\":  test_idx,\n",
    "            \"inner_folds\": inner_folds,\n",
    "            \"train_pos_ratio\": float(y_all[outer_tr_idx].mean()), # type: ignore\n",
    "            \"test_pos_ratio\":  float(y_all[outer_te_idx].mean()), # type: ignore\n",
    "        })\n",
    "\n",
    "    return nested\n",
    "\n",
    "    \n",
    "    \n",
    "cross_validation_sets = make_nested_cv_splits(birdclef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augments\n",
    "def aug_gaussian_noise_tf(audio, snr_db):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to a waveform at a given SNR (dB).\n",
    "    \n",
    "    Args:\n",
    "        audio (tf.Tensor): 1D or 2D waveform tensor (e.g. [time] or [batch, time]).\n",
    "        snr_db (float): Target signal-to-noise ratio in dB.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Noisy waveform with the specified SNR.\n",
    "    \"\"\"\n",
    "    # Calculate RMS of the signal\n",
    "    rms_signal = tf.sqrt(tf.reduce_mean(tf.square(audio), axis=-1, keepdims=True))\n",
    "\n",
    "    # Convert SNR from dB to linear scale\n",
    "    snr_linear = 10 ** (snr_db / 20.0)\n",
    "\n",
    "    # Desired noise RMS\n",
    "    rms_noise = rms_signal / snr_linear\n",
    "\n",
    "    # Generate Gaussian noise\n",
    "    noise = g1.normal(shape=tf.shape(audio), dtype=tf.float32)\n",
    "\n",
    "    # Normalize noise to unit RMS\n",
    "    rms_noise_current = tf.sqrt(tf.reduce_mean(tf.square(noise), axis=-1, keepdims=True))\n",
    "    noise = noise * (rms_noise / (rms_noise_current + 1e-8))\n",
    "\n",
    "    return audio + noise\n",
    "\n",
    "def aug_loudness_norm_tf(audio, target_db=-20.0, eps=1e-8):\n",
    "    rms = tf.sqrt(tf.reduce_mean(tf.square(audio), axis=-1, keepdims=True) + eps)\n",
    "    rms_db = 20.0 * tf.math.log(rms + eps) / tf.math.log(10.0)\n",
    "    gain = 10.0 ** ((target_db - rms_db) / 20.0)\n",
    "    return audio * gain\n",
    "\n",
    "def aug_specaugment_tf(spec, max_freq_masks=2, max_time_masks=2,\n",
    "                       max_freq_width=16, max_time_width=32):\n",
    "    spec = tf.identity(spec)\n",
    "    def _mask_freq(s):\n",
    "        f = tf.shape(s)[-2]; t = tf.shape(s)[-1]\n",
    "        w = g1.uniform((), 0, max_freq_width+1, dtype=tf.int32)\n",
    "        start = g1.uniform((), 0, tf.maximum(f - w, 1), dtype=tf.int32)\n",
    "        mask = tf.concat([tf.ones([start, t]), tf.zeros([w, t]), tf.ones([f - start - w, t])], axis=0)\n",
    "        return s * mask\n",
    "    def _mask_time(s):\n",
    "        f = tf.shape(s)[-2]; t = tf.shape(s)[-1]\n",
    "        w = g1.uniform((), 0, max_time_width+1, dtype=tf.int32)\n",
    "        start = g1.uniform((), 0, tf.maximum(t - w, 1), dtype=tf.int32)\n",
    "        mask = tf.concat([tf.ones([f, start]), tf.zeros([f, w]), tf.ones([f, t - start - w])], axis=1)\n",
    "        return s * mask\n",
    "    for _ in range(2):  # loop vars must be static; use fixed counts\n",
    "        spec = _mask_freq(spec)\n",
    "        spec = _mask_time(spec)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_onehot(y, num_classes):\n",
    "    # y can be [B] (int) or [B, 1] (int)\n",
    "    if y.dtype.is_integer:\n",
    "        y = tf.reshape(y, [-1])\n",
    "        y = tf.one_hot(y, depth=num_classes, dtype=tf.float32)\n",
    "    else:\n",
    "        # already one-hot or float\n",
    "        y = tf.cast(y, tf.float32)\n",
    "    return y\n",
    "\n",
    "def mixup_batch(x, y, alpha=0.2, num_classes=2):\n",
    "    \"\"\"\n",
    "    x: [B, ...]   (your mel: [B, N_MELS, N_FRAMES, 1])\n",
    "    y: [B] int, [B,1] int, or one-hot [B, C] / float labels\n",
    "    returns (x_mix, y_mix) with the same shapes as input (labels -> one-hot/float)\n",
    "    \"\"\"\n",
    "    B = tf.shape(x)[0]\n",
    "\n",
    "    # Sample lambda ~ Beta(alpha, alpha)\n",
    "    # Use two gammas trick (stable on TPU/GPU)\n",
    "    gamma1 = g1.gamma([], alpha, 1.0)\n",
    "    gamma2 = g1.gamma([], alpha, 1.0)\n",
    "    lam = gamma1 / (gamma1 + gamma2)  # scalar\n",
    "\n",
    "    # Permute the batch\n",
    "    idx = g1.uniform([B], minval=0, maxval=B, dtype=tf.int32)\n",
    "    x2 = tf.gather(x, idx)\n",
    "    y2 = tf.gather(y, idx)\n",
    "\n",
    "    # Ensure y is float one-hot (or float for binary)\n",
    "    y  = _to_onehot(y,  num_classes)\n",
    "    y2 = _to_onehot(y2, num_classes)\n",
    "\n",
    "    # Mix\n",
    "    lam_x = tf.cast(lam, x.dtype)\n",
    "    x_mix = lam_x * x + (1.0 - lam_x) * x2\n",
    "\n",
    "    lam_y = tf.cast(lam, tf.float32)\n",
    "    y_mix = lam_y * y + (1.0 - lam_y) * y2  # soft labels\n",
    "\n",
    "    return x_mix, y_mix\n",
    "\n",
    "def maybe_mixup(x, y, p=0.5, alpha=0.2, num_classes=2):\n",
    "    \"\"\"Apply mixup to a batch with probability p.\"\"\"\n",
    "    u = g1.uniform(())\n",
    "    return tf.cond(\n",
    "        u < p,\n",
    "        lambda: mixup_batch(x, y, alpha=alpha, num_classes=num_classes),\n",
    "        lambda: (x, _to_onehot(y, num_classes) if y.dtype.is_integer else tf.cast(y, tf.float32))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "512e7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def load_ogg_ffmpeg(path, sr=SAMPLE_RATE):\n",
    "    path = path.decode(\"utf-8\")\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-i\", path, \"-f\", \"f32le\",\n",
    "        \"-ac\", \"1\", \"-ar\", str(sr), \"pipe:1\", \"-loglevel\", \"quiet\"\n",
    "    ]\n",
    "    out = subprocess.check_output(cmd)\n",
    "    audio = np.frombuffer(out, np.float32)\n",
    "    return audio\n",
    "\n",
    "def load_ogg_librosa(path, sr=SAMPLE_RATE):\n",
    "    path = path.decode(\"utf-8\")\n",
    "    y, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "    return y\n",
    "\n",
    "from librosa._typing import _STFTPad\n",
    "\n",
    "def generate_mel_spectrogram(audio, sr = SAMPLE_RATE, n_fft=1024, n_mels=128, hop_length=512, win_length=None, \n",
    "                       window:str='hann', center=True, pad_mode:_STFTPad='constant', power=2.0, fmin=200, \n",
    "                       fmax=8000, norm='slaney'):\n",
    "    # Generate mel spectrogram\n",
    "    spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, n_mels=n_mels, hop_length=hop_length, win_length=win_length, window=window, center=center, pad_mode=pad_mode, power=power, fmin=fmin, fmax=fmax, norm=norm)\n",
    "    # Convert to dB\n",
    "    spec = librosa.power_to_db(spec, ref=np.max)\n",
    "    return spec\n",
    "\n",
    "def apply_with_prob(x, p, aug_fn):\n",
    "    \"\"\"aug_fn must be a zero-arg callable returning a tensor like x.\"\"\"\n",
    "    u = g1.uniform((), 0.0, 1.0)\n",
    "    return tf.cond(u < p, true_fn=aug_fn, false_fn=lambda: tf.identity(x))\n",
    "\n",
    "def audio_pipeline(filename: Sequence[str], augment=False, p_loud=0.5, p_gaus=0.5, p_spec=0.8, loud_range=(-26.0, -18.0), gaus_range=(5, 20)):\n",
    "    # Load audio file as tensor \n",
    "    audio_file = tf.numpy_function(load_ogg_librosa, [filename, SAMPLE_RATE], tf.float32)\n",
    "    \n",
    "    # Remove last dimension\n",
    "    waveform = audio_file[:SAMPLE_RATE * MAX_DURATION] # type: ignore\n",
    "    \n",
    "    processed = waveform[:SAMPLE_RATE * SECONDS]\n",
    "     \n",
    "    if augment:\n",
    "        # Loudness Normalization\n",
    "        targetDbfs = g1.uniform((), loud_range[0], loud_range[1])\n",
    "        processed = apply_with_prob(processed, p_loud, lambda: aug_loudness_norm_tf(processed, targetDbfs))\n",
    "        \n",
    "        # Add Gaussian noise    \n",
    "        gaussian_snr = g1.uniform([], gaus_range[0], gaus_range[1])\n",
    "        processed = apply_with_prob(processed, p_gaus, lambda: aug_gaussian_noise_tf(processed, gaussian_snr))\n",
    "        \n",
    "    \n",
    "    n = tf.shape(processed)[0]\n",
    "    # If shorter than desired, pad or tile\n",
    "    if FILL_TYPE == \"pad\":\n",
    "        pad = tf.maximum(0, SAMPLE_RATE * SECONDS - n)\n",
    "        processed = tf.pad(processed, paddings=[[0, pad]])\n",
    "    else:  # tile\n",
    "        repeats = tf.maximum(\n",
    "            1,\n",
    "            tf.cast(\n",
    "                tf.math.ceil((SAMPLE_RATE * SECONDS) / tf.cast(n, tf.float32)), tf.int32\n",
    "            ),\n",
    "        )\n",
    "        processed = tf.tile(processed, [repeats])\n",
    "        processed = processed[: SAMPLE_RATE * SECONDS]\n",
    "    \n",
    "    # Band filter\n",
    "    from scipy import signal\n",
    "    b, a = signal.butter(4, [200, 7999], fs=SAMPLE_RATE, btype='band')\n",
    "    band_filter = tf.py_function(signal.lfilter, [b, a, processed], Tout=tf.float32, name=\"Filter\")\n",
    "\n",
    "    db_mel_spectrogram = tf.numpy_function(\n",
    "        generate_mel_spectrogram, [band_filter, SAMPLE_RATE], Tout=tf.float32\n",
    "    )\n",
    "\n",
    "    db_mel_spectrogram = tf.ensure_shape(db_mel_spectrogram, shape=(N_MELS, N_FRAMES))\n",
    "\n",
    "    \n",
    "    return db_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ddbdd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "# --------- Simple binary CNN ----------\n",
    "def build_binary_cnn(\n",
    "    input_shape=(128, 64, 1),\n",
    "    lr=1e-3,\n",
    "    l2=1e-4,\n",
    "    dropout=0.25,\n",
    "    gamma=2.0,\n",
    "    alpha=0.25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Binary classifier for log-mel spectrograms (target vs non-target).\n",
    "    Output: single sigmoid unit.\n",
    "    Loss: Binary Focal Cross-Entropy (with safe fallbacks).\n",
    "    \"\"\"\n",
    "    L2 = keras.regularizers.l2(l2)\n",
    "    Conv = keras.layers.Conv2D\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv(32, (3, 3), padding=\"same\", kernel_regularizer=L2)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = Conv(32, (3, 3), padding=\"same\", kernel_regularizer=L2)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2))(x)   # 128x64 -> 64x32\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv(64, (3, 3), padding=\"same\", kernel_regularizer=L2)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = Conv(64, (3, 3), padding=\"same\", kernel_regularizer=L2)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2))(x)   # 64x32 -> 32x16\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv(96, (3, 3), padding=\"same\", kernel_regularizer=L2)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = Conv(96, (3, 3), padding=\"same\", kernel_regularizer=L2)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D((2, 2))(x)   # 32x16 -> 16x8\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "    # Head\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=L2)(x)\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)  # binary\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=keras.losses.BinaryFocalCrossentropy(\n",
    "            alpha=alpha,\n",
    "            gamma=gamma,\n",
    "            name='binary_focal_crossentropy'\n",
    "        ),\n",
    "        metrics=[\n",
    "            keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "            keras.metrics.BinaryAccuracy(name=\"acc\", threshold=0.5),\n",
    "            keras.metrics.AUC(curve=\"ROC\", name=\"auc\"),\n",
    "            keras.metrics.AUC(curve=\"PR\",  name=\"auprc\"),\n",
    "            keras.metrics.Precision(name=\"precision\", thresholds=0.5),\n",
    "            keras.metrics.Recall(name=\"recall\", thresholds=0.5),\n",
    "        ],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc68817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def _map_pos(x, y):\n",
    "    return audio_pipeline(x, augment=True), y\n",
    "\n",
    "def _map_neg(x, y):\n",
    "    return audio_pipeline(x, augment=True), y\n",
    "\n",
    "def plan_epoch_counts(n_pos_train: int, neg_pos_ratio: float = 2.0) -> Tuple[int, int]:\n",
    "    P_pos = int(n_pos_train)\n",
    "    P_neg = int(round(neg_pos_ratio * P_pos))\n",
    "    return P_pos, P_neg \n",
    "\n",
    "def sample_train_negatives(neg_all: Sequence[str], n_neg: int, seed: Optional[int] = None) -> Sequence[str]:\n",
    "    n = min(n_neg, len(neg_all))\n",
    "    rng = random.Random(seed)\n",
    "    return rng.sample(list(neg_all), n) if n > 0 else []\n",
    "\n",
    "def make_fixed_val_negatives(neg_all: Sequence[str], n_pos_val: int, neg_pos_ratio: int = NEG_POS_RATIO, seed: int = RANDOM_STATE) -> Sequence[str]:\n",
    "    n_neg = min(neg_pos_ratio * n_pos_val, len(neg_all))\n",
    "    rng = random.Random(seed)\n",
    "    return rng.sample(list(neg_all), n_neg) if n_neg > 0 else []\n",
    "\n",
    "STEPS_PER_TRAINING_EPOCH = 0\n",
    "STEPS_PER_VALIDATION_EPOCH = 0\n",
    "\n",
    "def build_train_dataset(pos_files: Sequence[str], neg_files: Sequence[str], batch_size: int = BATCH_SIZE, shuffle: bool = True) -> tf.data.Dataset:\n",
    "    global STEPS_PER_TRAINING_EPOCH\n",
    "    \n",
    "    labels_pos = tf.ones([len(pos_files)], dtype=tf.float32)\n",
    "    labels_neg = tf.zeros([len(neg_files)], dtype=tf.float32)\n",
    "    \n",
    "    ds_pos = tf.data.Dataset.from_tensor_slices((list(pos_files), labels_pos)).map(_map_pos, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_neg = tf.data.Dataset.from_tensor_slices((list(neg_files), labels_neg)).map(_map_neg, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Set the amount of steps\n",
    "    STEPS_PER_TRAINING_EPOCH = math.ceil((len(ds_pos) + len(ds_neg))/BATCH_SIZE)\n",
    "    ds = ds_pos.concatenate(ds_neg)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(pos_files) + len(neg_files), seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size).cache().repeat()\n",
    "    return ds\n",
    "\n",
    "\n",
    "def build_val_dataset(pos_files: Sequence[str], neg_files_fixed: Sequence[str], batch_size: int = BATCH_SIZE) -> tf.data.Dataset:\n",
    "    global STEPS_PER_VALIDATION_EPOCH\n",
    "\n",
    "    y_pos = tf.ones([len(pos_files)],        dtype=tf.float32)\n",
    "    y_neg = tf.zeros([len(neg_files_fixed)], dtype=tf.float32)\n",
    "\n",
    "    ds_pos = tf.data.Dataset.from_tensor_slices((list(pos_files), y_pos)).map(lambda x,y: (audio_pipeline(x, augment=False), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_neg = tf.data.Dataset.from_tensor_slices((list(neg_files_fixed), y_neg)).map(lambda x,y: (audio_pipeline(x, augment=False), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    STEPS_PER_VALIDATION_EPOCH = math.ceil((len(y_pos)) / BATCH_SIZE)\n",
    "\n",
    "    return ds_pos.concatenate(ds_neg).batch(batch_size).cache()\n",
    "\n",
    "def build_file_lists(df: pd.DataFrame, idx, target=TARGET):\n",
    "    sub = df.iloc[idx]\n",
    "    pos = sub[sub.primary_label == target][\"path\"].tolist()\n",
    "    neg = sub[sub.primary_label != target][\"path\"].tolist()\n",
    "    return pos, neg\n",
    "\n",
    "def make_epoch_train_dataset(pos_tr_all: Sequence[str], neg_tr_all: Sequence[str],\n",
    "                             neg_pos_ratio: float = 2.0, batch_size: int = BATCH_SIZE, seed: Optional[int] = RANDOM_STATE) -> tf.data.Dataset:\n",
    "    P_pos, P_neg = plan_epoch_counts(len(pos_tr_all), neg_pos_ratio)\n",
    "    neg_epoch = sample_train_negatives(neg_tr_all, P_neg, seed=seed)\n",
    "    return build_train_dataset(pos_tr_all, neg_epoch, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def make_fixed_val_dataset(pos_va_all: Sequence[str], neg_va_all: Sequence[str],\n",
    "                           neg_pos_ratio: int = 3, batch_size: int = BATCH_SIZE, seed: int = RANDOM_STATE) -> tf.data.Dataset:\n",
    "    neg_fixed = make_fixed_val_negatives(neg_va_all, len(pos_va_all), neg_pos_ratio=neg_pos_ratio, seed=seed)\n",
    "    return build_val_dataset(pos_va_all, neg_fixed, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def build_all_file_lists(df: pd.DataFrame, folds: dict, epoch: int = 0):\n",
    "    out = []\n",
    "    for fold in folds:\n",
    "        outer_fold = int(fold[\"outer_fold\"])\n",
    "        outer_train_idx = fold[\"outer_train_idx\"]\n",
    "        outer_test_idx = fold[\"outer_test_idx\"]\n",
    "    \n",
    "        # Build the file lists for the outer fold\n",
    "        pos_tr_all, neg_tr_all = build_file_lists(df, outer_train_idx)    \n",
    "        pos_test_all, neg_test_all = build_file_lists(df, outer_test_idx)\n",
    "    \n",
    "\n",
    "        # Rotate negatives each epoch via seed that depends on (outer, inner, epoch)\n",
    "        outer_train_ds = make_epoch_train_dataset(\n",
    "            pos_tr_all,\n",
    "            neg_tr_all,\n",
    "            neg_pos_ratio=TRAIN_NEG_RATIO,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            seed=outer_fold,\n",
    "        )\n",
    "\n",
    "        outer_test_ds = make_fixed_val_dataset(\n",
    "            pos_test_all,\n",
    "            neg_test_all,\n",
    "            neg_pos_ratio=VAL_NEG_RATIO,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            seed=outer_fold,  # fixed per outer fold\n",
    "        )\n",
    "    \n",
    "        \n",
    "        inner_list = []\n",
    "        for inner in fold[\"inner_folds\"]:\n",
    "            inner_fold = int(inner[\"inner_fold\"])\n",
    "            inner_train_idx = inner[\"inner_train_idx\"]\n",
    "            inner_val_idx   = inner[\"inner_val_idx\"]\n",
    "\n",
    "            pos_tr_all, neg_tr_all = build_file_lists(df, inner_train_idx)\n",
    "            pos_va_all, neg_va_all = build_file_lists(df, inner_val_idx)\n",
    "\n",
    "            # Rotate negatives each epoch via seed that depends on (outer, inner, epoch)\n",
    "            train_ds = make_epoch_train_dataset(\n",
    "                pos_tr_all,\n",
    "                neg_tr_all,\n",
    "                neg_pos_ratio=TRAIN_NEG_RATIO,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                seed=outer_fold * 100_000 + inner_fold * 1_000 + epoch,\n",
    "            )\n",
    "\n",
    "            # Fixed validation and test datasets (reproducible seeds per outer/inner)\n",
    "            val_ds = make_fixed_val_dataset(\n",
    "                pos_va_all,\n",
    "                neg_va_all,\n",
    "                neg_pos_ratio=VAL_NEG_RATIO,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                seed=outer_fold * 100_000 + inner_fold,\n",
    "            )\n",
    "\n",
    "            test_ds = make_fixed_val_dataset(\n",
    "                pos_test_all,\n",
    "                neg_test_all,\n",
    "                neg_pos_ratio=VAL_NEG_RATIO,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                seed=outer_fold,  # fixed per outer fold\n",
    "            )\n",
    "\n",
    "            inner_list.append({\n",
    "                \"inner_fold\": inner_fold,\n",
    "                \"train_ds\": train_ds,\n",
    "                \"val_ds\":   val_ds,\n",
    "                \"test_ds\":  test_ds,\n",
    "            })\n",
    "        out.append({\"outer_fold\": outer_fold, \"train_ds\":outer_train_ds, \"test_ds\":outer_test_ds, \"inner\": inner_list})\n",
    "    return out\n",
    "        \n",
    "\n",
    "datasets = build_all_file_lists(birdclef_df, cross_validation_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f923103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Running outer fold: 1\n",
      "[INFO]: Running inner fold: 1\n",
      "Epoch 1/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 10s/step - Brier score: 0.1948 - acc: 0.7500 - auc: 0.4714 - auprc: 0.2249 - loss: 0.2231 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 1: val_loss improved from None to 0.48267, saving model to output/best.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step - Brier score: 0.2227 - acc: 0.6562 - auc: 0.5419 - auprc: 0.2831 - loss: 0.2380 - precision: 0.3333 - recall: 0.2941 - val_Brier score: 0.2896 - val_acc: 0.5833 - val_auc: 0.5254 - val_auprc: 0.4438 - val_loss: 0.4827 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Brier score: 0.2263 - acc: 0.6094 - auc: 0.5698 - auprc: 0.4219 - loss: 0.2315 - precision: 0.3333 - recall: 0.1711\n",
      "Epoch 2: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - Brier score: 0.2420 - acc: 0.5625 - auc: 0.5431 - auprc: 0.4308 - loss: 0.2603 - precision: 0.3333 - recall: 0.1200 - val_Brier score: 0.3670 - val_acc: 0.5833 - val_auc: 0.5214 - val_auprc: 0.4413 - val_loss: 1.0999 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - Brier score: 0.2487 - acc: 0.4722 - auc: 0.3625 - auprc: 0.3113 - loss: 0.2312 - precision: 0.0938 - recall: 0.1500     \n",
      "Epoch 3: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - Brier score: 0.2365 - acc: 0.4444 - auc: 0.4750 - auprc: 0.2568 - loss: 0.2230 - precision: 0.1875 - recall: 0.3000 - val_Brier score: 0.4133 - val_acc: 0.5833 - val_auc: 0.5018 - val_auprc: 0.4308 - val_loss: 2.6877 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - Brier score: 0.2223 - acc: 0.6250 - auc: 0.6135 - auprc: 0.3593 - loss: 0.1993 - precision: 0.3636 - recall: 0.4444\n",
      "Epoch 4: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - Brier score: 0.2133 - acc: 0.7031 - auc: 0.6739 - auprc: 0.4009 - loss: 0.1902 - precision: 0.4706 - recall: 0.4444 - val_Brier score: 0.4163 - val_acc: 0.5833 - val_auc: 0.4911 - val_auprc: 0.4008 - val_loss: 4.0565 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - Brier score: 0.2798 - acc: 0.3750 - auc: 0.4062 - auprc: 0.4148 - loss: 0.2957 - precision: 0.2500 - recall: 0.1250\n",
      "Epoch 5: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - Brier score: 0.2735 - acc: 0.4167 - auc: 0.4491 - auprc: 0.4453 - loss: 0.2844 - precision: 0.3333 - recall: 0.1667 - val_Brier score: 0.4165 - val_acc: 0.5833 - val_auc: 0.5000 - val_auprc: 0.4167 - val_loss: 4.5686 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - Brier score: 0.2122 - acc: 0.6875 - auc: 0.6849 - auprc: 0.3462 - loss: 0.1833 - precision: 0.2500 - recall: 0.1250\n",
      "Epoch 6: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - Brier score: 0.2078 - acc: 0.7344 - auc: 0.7447 - auprc: 0.4262 - loss: 0.1793 - precision: 0.5000 - recall: 0.3529 - val_Brier score: 0.4166 - val_acc: 0.5833 - val_auc: 0.5000 - val_auprc: 0.4167 - val_loss: 5.3232 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - Brier score: 0.2233 - acc: 0.7188 - auc: 0.6135 - auprc: 0.5847 - loss: 0.1975 - precision: 0.5000 - recall: 0.4444\n",
      "Epoch 7: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - Brier score: 0.2317 - acc: 0.5938 - auc: 0.5723 - auprc: 0.4578 - loss: 0.2092 - precision: 0.4615 - recall: 0.2400 - val_Brier score: 0.4167 - val_acc: 0.5833 - val_auc: 0.5000 - val_auprc: 0.4167 - val_loss: 7.2246 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Brier score: 0.1604 - acc: 0.7500 - auc: 1.0000 - auprc: 1.0000 - loss: 0.1386 - precision: 1.0000 - recall: 0.5000\n",
      "Epoch 8: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - Brier score: 0.2028 - acc: 0.6944 - auc: 0.6827 - auprc: 0.3735 - loss: 0.1789 - precision: 0.4286 - recall: 0.3000 - val_Brier score: 0.4167 - val_acc: 0.5833 - val_auc: 0.5000 - val_auprc: 0.4167 - val_loss: 8.8641 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - Brier score: 0.2182 - acc: 0.6562 - auc: 0.6860 - auprc: 0.5107 - loss: 0.1916 - precision: 0.4167 - recall: 0.5556\n",
      "Epoch 9: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - Brier score: 0.2136 - acc: 0.6250 - auc: 0.6570 - auprc: 0.4241 - loss: 0.1892 - precision: 0.3750 - recall: 0.5000 - val_Brier score: 0.4167 - val_acc: 0.5833 - val_auc: 0.5000 - val_auprc: 0.4167 - val_loss: 9.4256 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "['loss', 'compile_metrics']\n",
      "[0.4033861756324768, 0.24172265827655792, 0.6666666865348816, 0.5061224699020386, 0.3319377899169922, 0.0, 0.0]\n",
      "[INFO]: Running inner fold: 2\n",
      "Epoch 1/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 9s/step - Brier score: 0.2642 - acc: 0.6875 - auc: 0.3705 - auprc: 0.2401 - loss: 0.5487 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 1: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step - Brier score: 0.2733 - acc: 0.6094 - auc: 0.4772 - auprc: 0.3423 - loss: 0.4307 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_Brier score: 0.4297 - val_acc: 0.5417 - val_auc: 0.6346 - val_auprc: 0.5886 - val_loss: 1.6027 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - Brier score: 0.2793 - acc: 0.5156 - auc: 0.5234 - auprc: 0.3839 - loss: 0.1964 - precision: 0.3378 - recall: 0.5941   \n",
      "Epoch 2: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - Brier score: 0.2794 - acc: 0.5000 - auc: 0.5173 - auprc: 0.3608 - loss: 0.1950 - precision: 0.3226 - recall: 0.5882 - val_Brier score: 0.4579 - val_acc: 0.5417 - val_auc: 0.5114 - val_auprc: 0.4908 - val_loss: 4.4806 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - Brier score: 0.2724 - acc: 0.4375 - auc: 0.4795 - auprc: 0.2965 - loss: 0.1750 - precision: 0.2778 - recall: 0.5000\n",
      "Epoch 3: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - Brier score: 0.2720 - acc: 0.4688 - auc: 0.4719 - auprc: 0.3449 - loss: 0.1900 - precision: 0.3514 - recall: 0.5652 - val_Brier score: 0.4583 - val_acc: 0.5417 - val_auc: 0.5000 - val_auprc: 0.4583 - val_loss: 6.3813 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - Brier score: 0.2128 - acc: 0.6875 - auc: 0.7318 - auprc: 0.6022 - loss: 0.1155 - precision: 0.5000 - recall: 0.7000\n",
      "Epoch 4: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - Brier score: 0.2296 - acc: 0.6071 - auc: 0.6139 - auprc: 0.3753 - loss: 0.1371 - precision: 0.3913 - recall: 0.5294 - val_Brier score: 0.4581 - val_acc: 0.5417 - val_auc: 0.5114 - val_auprc: 0.4908 - val_loss: 5.1862 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - Brier score: 0.2179 - acc: 0.6875 - auc: 0.6659 - auprc: 0.4461 - loss: 0.1141 - precision: 0.5000 - recall: 0.6000\n",
      "Epoch 5: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - Brier score: 0.2325 - acc: 0.6875 - auc: 0.6564 - auprc: 0.5016 - loss: 0.1492 - precision: 0.5714 - recall: 0.5217 - val_Brier score: 0.4489 - val_acc: 0.5417 - val_auc: 0.5911 - val_auprc: 0.5640 - val_loss: 2.3862 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - Brier score: 0.2356 - acc: 0.6562 - auc: 0.5955 - auprc: 0.3636 - loss: 0.1447 - precision: 0.4444 - recall: 0.4000\n",
      "Epoch 6: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - Brier score: 0.2392 - acc: 0.6607 - auc: 0.6161 - auprc: 0.3574 - loss: 0.1591 - precision: 0.4286 - recall: 0.3529 - val_Brier score: 0.4514 - val_acc: 0.5417 - val_auc: 0.5924 - val_auprc: 0.5578 - val_loss: 2.6193 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - Brier score: 0.2215 - acc: 0.6562 - auc: 0.6455 - auprc: 0.3862 - loss: 0.1270 - precision: 0.3333 - recall: 0.1000\n",
      "Epoch 7: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - Brier score: 0.2322 - acc: 0.5938 - auc: 0.5928 - auprc: 0.3878 - loss: 0.1392 - precision: 0.2857 - recall: 0.0870 - val_Brier score: 0.4575 - val_acc: 0.5417 - val_auc: 0.5227 - val_auprc: 0.5154 - val_loss: 4.3021 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - Brier score: 0.2470 - acc: 0.6250 - auc: 0.3545 - auprc: 0.2519 - loss: 0.1588 - precision: 0.2500 - recall: 0.1000\n",
      "Epoch 8: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - Brier score: 0.2391 - acc: 0.6250 - auc: 0.4284 - auprc: 0.2696 - loss: 0.1494 - precision: 0.2500 - recall: 0.1176 - val_Brier score: 0.4583 - val_acc: 0.5417 - val_auc: 0.5000 - val_auprc: 0.4583 - val_loss: 6.6727 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "['loss', 'compile_metrics']\n",
      "[1.2791959047317505, 0.3172115087509155, 0.6666666865348816, 0.5018367171287537, 0.32737359404563904, 0.0, 0.0]\n",
      "Inner CV mean test acc: 0.667\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - Brier score: 0.2760 - acc: 0.5625 - auc: 0.4793 - auprc: 0.3492 - loss: 0.4992 - precision: 0.3913 - recall: 0.3913\n",
      "Epoch 2/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - Brier score: 0.3133 - acc: 0.4062 - auc: 0.2969 - auprc: 0.1798 - loss: 0.5487 - precision: 0.1333 - recall: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joris/.pyenv/versions/3.12.11/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: Brier score,acc,auc,auprc,loss,precision,recall\n",
      "  current = self.get_monitor_value(logs)\n",
      "/home/joris/.pyenv/versions/3.12.11/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:276: UserWarning: Can save best model only with val_loss available.\n",
      "  if self._should_save_model(epoch, batch, logs, filepath):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - Brier score: 0.2567 - acc: 0.5938 - auc: 0.4662 - auprc: 0.2450 - loss: 0.4469 - precision: 0.3043 - recall: 0.4118\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - Brier score: 0.2597 - acc: 0.6094 - auc: 0.3949 - auprc: 0.2975 - loss: 0.5142 - precision: 0.2222 - recall: 0.1000\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - Brier score: 0.2572 - acc: 0.5667 - auc: 0.5347 - auprc: 0.3904 - loss: 0.4697 - precision: 0.2500 - recall: 0.0417         \n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - Brier score: 0.2329 - acc: 0.6094 - auc: 0.5514 - auprc: 0.4465 - loss: 0.3872 - precision: 0.4286 - recall: 0.2609\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - Brier score: 0.2755 - acc: 0.4531 - auc: 0.3411 - auprc: 0.2096 - loss: 0.4578 - precision: 0.1786 - recall: 0.2941\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - Brier score: 0.2446 - acc: 0.6250 - auc: 0.5767 - auprc: 0.3449 - loss: 0.3972 - precision: 0.3750 - recall: 0.3000\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - Brier score: 0.2380 - acc: 0.6000 - auc: 0.5845 - auprc: 0.5085 - loss: 0.3884 - precision: 0.5000 - recall: 0.2917\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - Brier score: 0.2205 - acc: 0.6406 - auc: 0.6113 - auprc: 0.4950 - loss: 0.3568 - precision: 0.5000 - recall: 0.1739      \n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - Brier score: 0.2173 - acc: 0.6719 - auc: 0.5081 - auprc: 0.2618 - loss: 0.3590 - precision: 0.2500 - recall: 0.1176\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - Brier score: 0.2189 - acc: 0.6562 - auc: 0.5659 - auprc: 0.3599 - loss: 0.3652 - precision: 0.2500 - recall: 0.0500\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - Brier score: 0.2295 - acc: 0.6500 - auc: 0.6001 - auprc: 0.5726 - loss: 0.3848 - precision: 0.8000 - recall: 0.1667\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - Brier score: 0.2267 - acc: 0.6719 - auc: 0.5737 - auprc: 0.5111 - loss: 0.3713 - precision: 0.7500 - recall: 0.1304\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - Brier score: 0.2223 - acc: 0.6875 - auc: 0.4962 - auprc: 0.2695 - loss: 0.3575 - precision: 0.2857 - recall: 0.1176\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - Brier score: 0.2066 - acc: 0.6875 - auc: 0.6722 - auprc: 0.4842 - loss: 0.3321 - precision: 0.5000 - recall: 0.1500\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Brier score: 0.2192 - acc: 0.6833 - auc: 0.6887 - auprc: 0.6546 - loss: 0.3560 - precision: 1.0000 - recall: 0.2083\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - Brier score: 0.2129 - acc: 0.6719 - auc: 0.7073 - auprc: 0.5839 - loss: 0.3376 - precision: 0.6667 - recall: 0.1739\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - Brier score: 0.2071 - acc: 0.6875 - auc: 0.6708 - auprc: 0.3527 - loss: 0.3289 - precision: 0.2857 - recall: 0.1176\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - Brier score: 0.2205 - acc: 0.7344 - auc: 0.5358 - auprc: 0.3956 - loss: 0.3617 - precision: 0.7143 - recall: 0.2500\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - Brier score: 0.2216 - acc: 0.6667 - auc: 0.6748 - auprc: 0.6294 - loss: 0.3637 - precision: 0.7500 - recall: 0.2500\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Brier score: 0.2134 - acc: 0.6562 - auc: 0.6713 - auprc: 0.5706 - loss: 0.3415 - precision: 0.5455 - recall: 0.2609\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Brier score: 0.2018 - acc: 0.7500 - auc: 0.7134 - auprc: 0.4699 - loss: 0.3210 - precision: 0.5333 - recall: 0.4706\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - Brier score: 0.2176 - acc: 0.6406 - auc: 0.6000 - auprc: 0.4017 - loss: 0.3543 - precision: 0.3636 - recall: 0.2000\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - Brier score: 0.2247 - acc: 0.6167 - auc: 0.6620 - auprc: 0.5444 - loss: 0.3627 - precision: 0.5455 - recall: 0.2500\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Brier score: 0.2112 - acc: 0.6719 - auc: 0.7036 - auprc: 0.5543 - loss: 0.3442 - precision: 0.5833 - recall: 0.3043\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - Brier score: 0.1982 - acc: 0.7031 - auc: 0.6740 - auprc: 0.4054 - loss: 0.3207 - precision: 0.4000 - recall: 0.2353\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - Brier score: 0.2003 - acc: 0.6875 - auc: 0.6977 - auprc: 0.5373 - loss: 0.3230 - precision: 0.5000 - recall: 0.2000\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - Brier score: 0.2191 - acc: 0.6333 - auc: 0.7205 - auprc: 0.5827 - loss: 0.3528 - precision: 0.6250 - recall: 0.2083\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - Brier score: 0.2180 - acc: 0.6875 - auc: 0.6463 - auprc: 0.5882 - loss: 0.3520 - precision: 0.8000 - recall: 0.1739\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - Brier score: 0.1971 - acc: 0.7500 - auc: 0.6996 - auprc: 0.4524 - loss: 0.3153 - precision: 0.5556 - recall: 0.2941\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - Brier score: 0.2177 - acc: 0.6406 - auc: 0.6341 - auprc: 0.3661 - loss: 0.3557 - precision: 0.3333 - recall: 0.1500\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - Brier score: 0.2216 - acc: 0.5667 - auc: 0.6881 - auprc: 0.5111 - loss: 0.3609 - precision: 0.3333 - recall: 0.0833       \n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - Brier score: 0.2077 - acc: 0.7344 - auc: 0.6972 - auprc: 0.6139 - loss: 0.3349 - precision: 0.8000 - recall: 0.3478\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Brier score: 0.1978 - acc: 0.7500 - auc: 0.6840 - auprc: 0.4474 - loss: 0.3159 - precision: 0.5714 - recall: 0.2353\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Brier score: 0.2019 - acc: 0.6562 - auc: 0.7585 - auprc: 0.4666 - loss: 0.3224 - precision: 0.3750 - recall: 0.1500\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - Brier score: 0.2088 - acc: 0.6500 - auc: 0.7708 - auprc: 0.6620 - loss: 0.3372 - precision: 0.8000 - recall: 0.1667\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - Brier score: 0.2044 - acc: 0.6875 - auc: 0.7550 - auprc: 0.6235 - loss: 0.3303 - precision: 0.8000 - recall: 0.1739\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Brier score: 0.1867 - acc: 0.7656 - auc: 0.7641 - auprc: 0.5032 - loss: 0.2993 - precision: 0.6000 - recall: 0.3529\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - Brier score: 0.1893 - acc: 0.7188 - auc: 0.7790 - auprc: 0.5182 - loss: 0.3043 - precision: 0.6667 - recall: 0.2000\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - Brier score: 0.1965 - acc: 0.6833 - auc: 0.7841 - auprc: 0.7274 - loss: 0.3181 - precision: 0.7273 - recall: 0.3333\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - Brier score: 0.1936 - acc: 0.7188 - auc: 0.7609 - auprc: 0.6987 - loss: 0.3143 - precision: 0.7778 - recall: 0.3043\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Brier score: 0.1799 - acc: 0.7969 - auc: 0.7728 - auprc: 0.6485 - loss: 0.2879 - precision: 0.6667 - recall: 0.4706\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Brier score: 0.1805 - acc: 0.7344 - auc: 0.7795 - auprc: 0.6351 - loss: 0.2917 - precision: 0.6154 - recall: 0.4000\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - Brier score: 0.1965 - acc: 0.6500 - auc: 0.8119 - auprc: 0.7153 - loss: 0.3199 - precision: 0.7143 - recall: 0.2083\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - Brier score: 0.1864 - acc: 0.7188 - auc: 0.8261 - auprc: 0.7606 - loss: 0.3028 - precision: 0.8571 - recall: 0.2609\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - Brier score: 0.1707 - acc: 0.8750 - auc: 0.8323 - auprc: 0.7624 - loss: 0.2732 - precision: 0.9091 - recall: 0.5882\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - Brier score: 0.1741 - acc: 0.7812 - auc: 0.8438 - auprc: 0.6600 - loss: 0.2799 - precision: 0.7143 - recall: 0.5000\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - Brier score: 0.1784 - acc: 0.7833 - auc: 0.8686 - auprc: 0.7908 - loss: 0.2904 - precision: 0.8667 - recall: 0.5417\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - Brier score: 0.1763 - acc: 0.7969 - auc: 0.8192 - auprc: 0.7895 - loss: 0.2872 - precision: 0.8571 - recall: 0.5217\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - Brier score: 0.1626 - acc: 0.7812 - auc: 0.8504 - auprc: 0.7081 - loss: 0.2618 - precision: 0.6000 - recall: 0.5294\n",
      "[INFO]: Running outer fold: 2\n",
      "[INFO]: Running inner fold: 1\n",
      "Epoch 1/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 10s/step - Brier score: 0.3564 - acc: 0.3438 - auc: 0.4167 - auprc: 0.3108 - loss: 0.5099 - precision: 0.3448 - recall: 0.8333\n",
      "Epoch 1: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - Brier score: 0.3470 - acc: 0.3438 - auc: 0.3477 - auprc: 0.3098 - loss: 0.4632 - precision: 0.3023 - recall: 0.5200 - val_Brier score: 0.3880 - val_acc: 0.3333 - val_auc: 0.4707 - val_auprc: 0.2993 - val_loss: 0.5479 - val_precision: 0.3333 - val_recall: 1.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - Brier score: 0.2562 - acc: 0.6875 - auc: 0.3880 - auprc: 0.2067 - loss: 0.2902 - precision: 0.3333 - recall: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joris/.pyenv/versions/3.12.11/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - Brier score: 0.2421 - acc: 0.6797 - auc: 0.4593 - auprc: 0.2465 - loss: 0.2685 - precision: 0.3452 - recall: 0.2721 \n",
      "Epoch 2: val_loss did not improve from 0.48267\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - Brier score: 0.2280 - acc: 0.6719 - auc: 0.5307 - auprc: 0.2863 - loss: 0.2468 - precision: 0.3571 - recall: 0.2941 - val_Brier score: 0.4275 - val_acc: 0.3333 - val_auc: 0.4738 - val_auprc: 0.3020 - val_loss: 0.6956 - val_precision: 0.3333 - val_recall: 1.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - Brier score: 0.2748 - acc: 0.5357 - auc: 0.4250 - auprc: 0.3115 - loss: 0.3598 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 0.48267 to 0.25331, saving model to output/best.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - Brier score: 0.2551 - acc: 0.5667 - auc: 0.4856 - auprc: 0.3638 - loss: 0.3196 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_Brier score: 0.2750 - val_acc: 0.3333 - val_auc: 0.4699 - val_auprc: 0.3042 - val_loss: 0.2533 - val_precision: 0.3333 - val_recall: 1.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - Brier score: 0.2751 - acc: 0.5625 - auc: 0.4211 - auprc: 0.4157 - loss: 0.3665 - precision: 0.3333 - recall: 0.0769\n",
      "Epoch 4: val_loss improved from 0.25331 to 0.21084, saving model to output/best.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - Brier score: 0.2420 - acc: 0.6250 - auc: 0.4695 - auprc: 0.3187 - loss: 0.2860 - precision: 0.2857 - recall: 0.0952 - val_Brier score: 0.2458 - val_acc: 0.6667 - val_auc: 0.4082 - val_auprc: 0.2672 - val_loss: 0.2108 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - Brier score: 0.2120 - acc: 0.6875 - auc: 0.6039 - auprc: 0.4399 - loss: 0.1922 - precision: 0.4286 - recall: 0.3333\n",
      "Epoch 5: val_loss improved from 0.21084 to 0.20527, saving model to output/best.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - Brier score: 0.2222 - acc: 0.6833 - auc: 0.6297 - auprc: 0.3981 - loss: 0.2096 - precision: 0.5000 - recall: 0.3684 - val_Brier score: 0.2330 - val_acc: 0.6667 - val_auc: 0.4576 - val_auprc: 0.2901 - val_loss: 0.2053 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Brier score: 0.2135 - acc: 0.6875 - auc: 0.7333 - auprc: 0.6067 - loss: 0.2161 - precision: 0.6667 - recall: 0.3333\n",
      "Epoch 6: val_loss did not improve from 0.20527\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - Brier score: 0.2216 - acc: 0.6250 - auc: 0.6821 - auprc: 0.5561 - loss: 0.2156 - precision: 0.5294 - recall: 0.3600 - val_Brier score: 0.2241 - val_acc: 0.6667 - val_auc: 0.5108 - val_auprc: 0.3570 - val_loss: 0.2696 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - Brier score: 0.2413 - acc: 0.7188 - auc: 0.5365 - auprc: 0.2831 - loss: 0.2285 - precision: 0.4545 - recall: 0.6250\n",
      "Epoch 7: val_loss did not improve from 0.20527\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - Brier score: 0.2262 - acc: 0.7031 - auc: 0.6039 - auprc: 0.3347 - loss: 0.2079 - precision: 0.4500 - recall: 0.5294 - val_Brier score: 0.2513 - val_acc: 0.6667 - val_auc: 0.5231 - val_auprc: 0.3810 - val_loss: 0.4823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - Brier score: 0.2653 - acc: 0.4286 - auc: 0.3111 - auprc: 0.2578 - loss: 0.2517 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8: val_loss did not improve from 0.20527\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - Brier score: 0.2381 - acc: 0.5500 - auc: 0.5395 - auprc: 0.3656 - loss: 0.2185 - precision: 0.3077 - recall: 0.1818 - val_Brier score: 0.2902 - val_acc: 0.6667 - val_auc: 0.5301 - val_auprc: 0.4136 - val_loss: 0.8448 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - Brier score: 0.2506 - acc: 0.5938 - auc: 0.4534 - auprc: 0.3962 - loss: 0.2367 - precision: 0.5000 - recall: 0.2308\n",
      "Epoch 9: val_loss did not improve from 0.20527\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - Brier score: 0.2350 - acc: 0.6094 - auc: 0.5498 - auprc: 0.3505 - loss: 0.2260 - precision: 0.3571 - recall: 0.2381 - val_Brier score: 0.3132 - val_acc: 0.6667 - val_auc: 0.5255 - val_auprc: 0.4144 - val_loss: 1.2382 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - Brier score: 0.2021 - acc: 0.7188 - auc: 0.7053 - auprc: 0.5511 - loss: 0.1780 - precision: 0.5000 - recall: 0.3333\n",
      "Epoch 10: val_loss did not improve from 0.20527\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - Brier score: 0.2024 - acc: 0.7167 - auc: 0.7356 - auprc: 0.5504 - loss: 0.1797 - precision: 0.5833 - recall: 0.3684 - val_Brier score: 0.3230 - val_acc: 0.6667 - val_auc: 0.5455 - val_auprc: 0.3980 - val_loss: 1.5768 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - Brier score: 0.2064 - acc: 0.7188 - auc: 0.7021 - auprc: 0.6549 - loss: 0.1993 - precision: 0.8000 - recall: 0.3333\n",
      "Epoch 11: val_loss did not improve from 0.20527\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - Brier score: 0.2148 - acc: 0.6719 - auc: 0.6851 - auprc: 0.6311 - loss: 0.2120 - precision: 0.7500 - recall: 0.2400 - val_Brier score: 0.3289 - val_acc: 0.6667 - val_auc: 0.4738 - val_auprc: 0.3687 - val_loss: 2.0062 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - Brier score: 0.2037 - acc: 0.6875 - auc: 0.6875 - auprc: 0.3789 - loss: 0.1893 - precision: 0.4000 - recall: 0.5000\n",
      "Epoch 12: val_loss did not improve from 0.20527\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - Brier score: 0.2020 - acc: 0.7344 - auc: 0.7190 - auprc: 0.4540 - loss: 0.1872 - precision: 0.5000 - recall: 0.4706 - val_Brier score: 0.3316 - val_acc: 0.6667 - val_auc: 0.5285 - val_auprc: 0.3715 - val_loss: 2.4969 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - Brier score: 0.1881 - acc: 0.7143 - auc: 0.8167 - auprc: 0.7574 - loss: 0.1670 - precision: 0.6000 - recall: 0.6000\n",
      "Epoch 13: val_loss did not improve from 0.20527\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - Brier score: 0.1980 - acc: 0.7167 - auc: 0.7763 - auprc: 0.7268 - loss: 0.1788 - precision: 0.6471 - recall: 0.5000 - val_Brier score: 0.3325 - val_acc: 0.6667 - val_auc: 0.5417 - val_auprc: 0.4063 - val_loss: 2.8951 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "['loss', 'compile_metrics']\n",
      "[0.2042880356311798, 0.23176193237304688, 0.6666666865348816, 0.49907881021499634, 0.3225383758544922, 0.0, 0.0]\n",
      "[INFO]: Running inner fold: 2\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - Brier score: 0.2332 - acc: 0.5810 - auc: 0.5812 - auprc: 0.3842 - loss: 0.1511 - precision: 0.2821 - recall: 0.1288\n",
      "Epoch 1: val_loss improved from 0.20527 to 0.13739, saving model to output/best.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9s/step - Brier score: 0.2506 - acc: 0.5370 - auc: 0.5131 - auprc: 0.3121 - loss: 0.1657 - precision: 0.2308 - recall: 0.1667 - val_Brier score: 0.2472 - val_acc: 0.5417 - val_auc: 0.5819 - val_auprc: 0.6318 - val_loss: 0.1374 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - Brier score: 0.2442 - acc: 0.5938 - auc: 0.5303 - auprc: 0.3320 - loss: 0.1924 - precision: 0.3750 - recall: 0.2727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 20:59:48.194136: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 0.13739\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - Brier score: 0.2405 - acc: 0.6296 - auc: 0.5556 - auprc: 0.3569 - loss: 0.1924 - precision: 0.4286 - recall: 0.3333 - val_Brier score: 0.3441 - val_acc: 0.5417 - val_auc: 0.5789 - val_auprc: 0.6283 - val_loss: 0.6111 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - Brier score: 0.2169 - acc: 0.5341 - auc: 0.6405 - auprc: 0.4362 - loss: 0.1250 - precision: 0.2159 - recall: 0.1465 \n",
      "Epoch 3: val_loss did not improve from 0.13739\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - Brier score: 0.2219 - acc: 0.5370 - auc: 0.6057 - auprc: 0.4027 - loss: 0.1313 - precision: 0.1818 - recall: 0.1111 - val_Brier score: 0.3307 - val_acc: 0.5417 - val_auc: 0.5846 - val_auprc: 0.6323 - val_loss: 0.5316 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - Brier score: 0.2373 - acc: 0.5938 - auc: 0.6082 - auprc: 0.5024 - loss: 0.1385 - precision: 0.4167 - recall: 0.4545\n",
      "Epoch 4: val_loss did not improve from 0.13739\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - Brier score: 0.2367 - acc: 0.6296 - auc: 0.6535 - auprc: 0.4579 - loss: 0.1387 - precision: 0.4545 - recall: 0.5556 - val_Brier score: 0.3561 - val_acc: 0.5417 - val_auc: 0.5911 - val_auprc: 0.6409 - val_loss: 0.6989 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - Brier score: 0.2318 - acc: 0.6562 - auc: 0.5931 - auprc: 0.4709 - loss: 0.1308 - precision: 0.5000 - recall: 0.2727\n",
      "Epoch 5: val_loss improved from 0.13739 to 0.12933, saving model to output/best.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - Brier score: 0.2184 - acc: 0.7222 - auc: 0.6582 - auprc: 0.5831 - loss: 0.1265 - precision: 0.6364 - recall: 0.3889 - val_Brier score: 0.2451 - val_acc: 0.5521 - val_auc: 0.6025 - val_auprc: 0.6592 - val_loss: 0.1293 - val_precision: 0.5474 - val_recall: 1.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - Brier score: 0.2177 - acc: 0.6250 - auc: 0.6970 - auprc: 0.5109 - loss: 0.1194 - precision: 0.4000 - recall: 0.1818\n",
      "Epoch 6: val_loss did not improve from 0.12933\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - Brier score: 0.2152 - acc: 0.6296 - auc: 0.6728 - auprc: 0.5036 - loss: 0.1223 - precision: 0.3750 - recall: 0.1667 - val_Brier score: 0.3916 - val_acc: 0.4583 - val_auc: 0.4224 - val_auprc: 0.5039 - val_loss: 0.6276 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - Brier score: 0.2228 - acc: 0.6875 - auc: 0.7251 - auprc: 0.6518 - loss: 0.1688 - precision: 0.5556 - recall: 0.4545\n",
      "Epoch 7: val_loss did not improve from 0.12933\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - Brier score: 0.2244 - acc: 0.6481 - auc: 0.6566 - auprc: 0.5376 - loss: 0.1531 - precision: 0.4615 - recall: 0.3333 - val_Brier score: 0.2862 - val_acc: 0.4583 - val_auc: 0.4598 - val_auprc: 0.5138 - val_loss: 0.2075 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - Brier score: 0.2369 - acc: 0.4688 - auc: 0.5606 - auprc: 0.4168 - loss: 0.1322 - precision: 0.2000 - recall: 0.1818\n",
      "Epoch 8: val_loss did not improve from 0.12933\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - Brier score: 0.2240 - acc: 0.5741 - auc: 0.6605 - auprc: 0.4756 - loss: 0.1208 - precision: 0.3684 - recall: 0.3889 - val_Brier score: 0.2762 - val_acc: 0.5417 - val_auc: 0.5942 - val_auprc: 0.6453 - val_loss: 0.2678 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - Brier score: 0.2248 - acc: 0.6562 - auc: 0.6948 - auprc: 0.5621 - loss: 0.1198 - precision: 0.5000 - recall: 0.6364\n",
      "Epoch 9: val_loss did not improve from 0.12933\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - Brier score: 0.2234 - acc: 0.6667 - auc: 0.6721 - auprc: 0.5161 - loss: 0.1224 - precision: 0.5000 - recall: 0.5000 - val_Brier score: 0.3286 - val_acc: 0.5417 - val_auc: 0.5920 - val_auprc: 0.6410 - val_loss: 0.5241 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - Brier score: 0.2177 - acc: 0.6562 - auc: 0.6905 - auprc: 0.4448 - loss: 0.1167 - precision: 0.5000 - recall: 0.3636\n",
      "Epoch 10: val_loss did not improve from 0.12933\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - Brier score: 0.2167 - acc: 0.6667 - auc: 0.7052 - auprc: 0.4509 - loss: 0.1176 - precision: 0.5000 - recall: 0.3333 - val_Brier score: 0.3147 - val_acc: 0.5417 - val_auc: 0.5894 - val_auprc: 0.6434 - val_loss: 0.4489 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - Brier score: 0.2100 - acc: 0.7188 - auc: 0.7641 - auprc: 0.5937 - loss: 0.1119 - precision: 0.6250 - recall: 0.4545\n",
      "Epoch 11: val_loss did not improve from 0.12933\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - Brier score: 0.2097 - acc: 0.7222 - auc: 0.6975 - auprc: 0.5870 - loss: 0.1164 - precision: 0.6154 - recall: 0.4444 - val_Brier score: 0.3042 - val_acc: 0.5417 - val_auc: 0.5940 - val_auprc: 0.6480 - val_loss: 0.3975 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - Brier score: 0.2146 - acc: 0.6875 - auc: 0.6905 - auprc: 0.6212 - loss: 0.1165 - precision: 0.5556 - recall: 0.4545\n",
      "Epoch 12: val_loss did not improve from 0.12933\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - Brier score: 0.1990 - acc: 0.7222 - auc: 0.7608 - auprc: 0.6787 - loss: 0.1078 - precision: 0.6000 - recall: 0.5000 - val_Brier score: 0.3318 - val_acc: 0.5417 - val_auc: 0.6014 - val_auprc: 0.6558 - val_loss: 0.5470 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - Brier score: 0.2035 - acc: 0.7500 - auc: 0.7879 - auprc: 0.7244 - loss: 0.1135 - precision: 1.0000 - recall: 0.2727\n",
      "Epoch 13: val_loss did not improve from 0.12933\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - Brier score: 0.1990 - acc: 0.7407 - auc: 0.7855 - auprc: 0.5957 - loss: 0.1121 - precision: 0.8333 - recall: 0.2778 - val_Brier score: 0.3675 - val_acc: 0.5417 - val_auc: 0.6071 - val_auprc: 0.6589 - val_loss: 0.7989 - val_precision: 0.5417 - val_recall: 1.0000\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "['loss', 'compile_metrics']\n",
      "[0.1436873972415924, 0.2641928195953369, 0.3373015820980072, 0.5271045565605164, 0.34865689277648926, 0.3346613645553589, 1.0]\n",
      "Inner CV mean test acc: 0.502\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 151ms/step - Brier score: 0.2205 - acc: 0.6875 - auc: 0.6700 - auprc: 0.4770 - loss: 0.3675 - precision: 0.5200 - recall: 0.6190\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - Brier score: 0.2818 - acc: 0.5781 - auc: 0.4406 - auprc: 0.3663 - loss: 0.6111 - precision: 0.3333 - recall: 0.1250\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - Brier score: 0.2762 - acc: 0.4688 - auc: 0.3068 - auprc: 0.2579 - loss: 0.4613 - precision: 0.1667 - recall: 0.1364       \n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 228ms/step - Brier score: 0.2437 - acc: 0.6000 - auc: 0.5248 - auprc: 0.3234 - loss: 0.3901 - precision: 0.3889 - recall: 0.4375\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - Brier score: 0.2404 - acc: 0.6250 - auc: 0.3898 - auprc: 0.2619 - loss: 0.3945 - precision: 0.1667 - recall: 0.0500      \n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - Brier score: 0.2478 - acc: 0.5781 - auc: 0.5590 - auprc: 0.4375 - loss: 0.4290 - precision: 0.2500 - recall: 0.0400\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - Brier score: 0.2014 - acc: 0.7000 - auc: 0.6360 - auprc: 0.2859 - loss: 0.3223 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - Brier score: 0.2388 - acc: 0.6562 - auc: 0.3610 - auprc: 0.2485 - loss: 0.4017 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - Brier score: 0.2339 - acc: 0.6250 - auc: 0.5911 - auprc: 0.5490 - loss: 0.4137 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - Brier score: 0.2212 - acc: 0.6094 - auc: 0.5828 - auprc: 0.3742 - loss: 0.3581 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - Brier score: 0.2291 - acc: 0.6600 - auc: 0.5257 - auprc: 0.3261 - loss: 0.3744 - precision: 0.3333 - recall: 0.0625      \n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - Brier score: 0.2428 - acc: 0.6406 - auc: 0.4108 - auprc: 0.2668 - loss: 0.4065 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - Brier score: 0.2141 - acc: 0.6719 - auc: 0.7446 - auprc: 0.7074 - loss: 0.3413 - precision: 0.8333 - recall: 0.2000\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - Brier score: 0.2116 - acc: 0.7400 - auc: 0.5406 - auprc: 0.2781 - loss: 0.3366 - precision: 0.4286 - recall: 0.2500\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - Brier score: 0.2318 - acc: 0.6250 - auc: 0.4673 - auprc: 0.2998 - loss: 0.3764 - precision: 0.2857 - recall: 0.0952\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - Brier score: 0.2215 - acc: 0.6875 - auc: 0.6604 - auprc: 0.5990 - loss: 0.3708 - precision: 0.8333 - recall: 0.2083\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - Brier score: 0.2145 - acc: 0.6875 - auc: 0.6715 - auprc: 0.5247 - loss: 0.3422 - precision: 0.7500 - recall: 0.1364\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - Brier score: 0.2218 - acc: 0.6600 - auc: 0.5349 - auprc: 0.3318 - loss: 0.3611 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - Brier score: 0.2263 - acc: 0.6719 - auc: 0.4790 - auprc: 0.3060 - loss: 0.3691 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - Brier score: 0.2177 - acc: 0.6719 - auc: 0.7451 - auprc: 0.7317 - loss: 0.3507 - precision: 1.0000 - recall: 0.1600\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - Brier score: 0.1913 - acc: 0.7800 - auc: 0.7094 - auprc: 0.4920 - loss: 0.3038 - precision: 0.6667 - recall: 0.1667\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - Brier score: 0.2150 - acc: 0.6875 - auc: 0.6141 - auprc: 0.4865 - loss: 0.3446 - precision: 0.6000 - recall: 0.1429\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - Brier score: 0.2112 - acc: 0.6719 - auc: 0.7411 - auprc: 0.5699 - loss: 0.3360 - precision: 0.6364 - recall: 0.2917\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - Brier score: 0.2093 - acc: 0.6562 - auc: 0.7094 - auprc: 0.5424 - loss: 0.3335 - precision: 0.5000 - recall: 0.0909\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - Brier score: 0.2156 - acc: 0.6400 - auc: 0.6360 - auprc: 0.3894 - loss: 0.3471 - precision: 0.3333 - recall: 0.1250\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - Brier score: 0.2054 - acc: 0.7188 - auc: 0.6653 - auprc: 0.5097 - loss: 0.3362 - precision: 1.0000 - recall: 0.1000       \n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - Brier score: 0.1971 - acc: 0.7031 - auc: 0.8015 - auprc: 0.7500 - loss: 0.3230 - precision: 0.8750 - recall: 0.2800\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - Brier score: 0.1822 - acc: 0.8200 - auc: 0.7116 - auprc: 0.4504 - loss: 0.2929 - precision: 0.8000 - recall: 0.3333\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - Brier score: 0.2111 - acc: 0.6719 - auc: 0.6517 - auprc: 0.4400 - loss: 0.3422 - precision: 0.5000 - recall: 0.1905\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - Brier score: 0.1937 - acc: 0.7188 - auc: 0.8031 - auprc: 0.7360 - loss: 0.3234 - precision: 0.8750 - recall: 0.2917\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - Brier score: 0.1994 - acc: 0.7188 - auc: 0.7332 - auprc: 0.6135 - loss: 0.3244 - precision: 0.8333 - recall: 0.2273\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - Brier score: 0.1909 - acc: 0.7600 - auc: 0.7344 - auprc: 0.6156 - loss: 0.3112 - precision: 0.7500 - recall: 0.3750\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - Brier score: 0.1726 - acc: 0.7969 - auc: 0.8142 - auprc: 0.7492 - loss: 0.2860 - precision: 0.7692 - recall: 0.5000\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - Brier score: 0.1743 - acc: 0.7812 - auc: 0.8749 - auprc: 0.8331 - loss: 0.2849 - precision: 0.9231 - recall: 0.4800\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - Brier score: 0.1770 - acc: 0.8200 - auc: 0.7456 - auprc: 0.5993 - loss: 0.2865 - precision: 0.7143 - recall: 0.4167\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - Brier score: 0.1944 - acc: 0.6875 - auc: 0.7470 - auprc: 0.6073 - loss: 0.3175 - precision: 0.5385 - recall: 0.3333\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - Brier score: 0.1561 - acc: 0.8125 - auc: 0.9302 - auprc: 0.9187 - loss: 0.2545 - precision: 1.0000 - recall: 0.5000\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - Brier score: 0.1859 - acc: 0.7500 - auc: 0.7998 - auprc: 0.6379 - loss: 0.3022 - precision: 0.7500 - recall: 0.4091\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - Brier score: 0.1995 - acc: 0.7000 - auc: 0.7142 - auprc: 0.5177 - loss: 0.3275 - precision: 0.5455 - recall: 0.3750\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - Brier score: 0.1528 - acc: 0.8438 - auc: 0.8977 - auprc: 0.8275 - loss: 0.2483 - precision: 0.8571 - recall: 0.6000\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - Brier score: 0.1534 - acc: 0.8125 - auc: 0.9108 - auprc: 0.8734 - loss: 0.2574 - precision: 0.9333 - recall: 0.5600\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - Brier score: 0.1491 - acc: 0.8600 - auc: 0.8596 - auprc: 0.7567 - loss: 0.2453 - precision: 0.8571 - recall: 0.5000\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - Brier score: 0.1879 - acc: 0.7031 - auc: 0.7409 - auprc: 0.6336 - loss: 0.3130 - precision: 0.5556 - recall: 0.4762\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - Brier score: 0.1358 - acc: 0.8594 - auc: 0.9156 - auprc: 0.9267 - loss: 0.2348 - precision: 1.0000 - recall: 0.6250\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - Brier score: 0.1659 - acc: 0.8125 - auc: 0.8382 - auprc: 0.7820 - loss: 0.2778 - precision: 0.8125 - recall: 0.5909\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - Brier score: 0.1683 - acc: 0.7800 - auc: 0.8107 - auprc: 0.6940 - loss: 0.2843 - precision: 0.7778 - recall: 0.4375\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - Brier score: 0.1364 - acc: 0.8594 - auc: 0.9222 - auprc: 0.8303 - loss: 0.2284 - precision: 0.9231 - recall: 0.6000\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - Brier score: 0.1380 - acc: 0.8438 - auc: 0.9574 - auprc: 0.9410 - loss: 0.2309 - precision: 1.0000 - recall: 0.6000\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - Brier score: 0.1496 - acc: 0.8200 - auc: 0.8925 - auprc: 0.7813 - loss: 0.2420 - precision: 0.6154 - recall: 0.6667\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - Brier score: 0.1735 - acc: 0.7500 - auc: 0.8023 - auprc: 0.6643 - loss: 0.2890 - precision: 0.6316 - recall: 0.5714\n",
      "[0.36666667461395264, 0.64682537317276]\n"
     ]
    }
   ],
   "source": [
    "per_fold_results = []\n",
    "\n",
    "EPOCHS_PER_FOLD = 50\n",
    "\n",
    "hparams_per_fold = {\n",
    "    0: {\"lr\":1e-3, \"gamma\":1.0, \"alpha\":0.25},\n",
    "    1: {\"lr\":1e-3, \"gamma\":2.0, \"alpha\":0.5},\n",
    "    2: {\"lr\":1e-3, \"gamma\":3.0, \"alpha\":0.75},\n",
    "    3: {\"lr\":1e-3, \"gamma\":4.0, \"alpha\":0.25},\n",
    "    4: {\"lr\":1e-3, \"gamma\":5.0, \"alpha\":0.25},\n",
    "}\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=8, min_delta=1e-3, restore_best_weights=True, verbose=1)\n",
    "ckpt  = ModelCheckpoint(\"output/best.keras\", monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "for outer_fold in datasets:\n",
    "    print(f\"[INFO]: Running outer fold: {outer_fold[\"outer_fold\"]}\")\n",
    "    inner_scores = []\n",
    "    for inner_fold in outer_fold[\"inner\"]:\n",
    "        print(f\"[INFO]: Running inner fold: {inner_fold[\"inner_fold\"]}\")\n",
    "        model = build_binary_cnn(input_shape=INPUT_SHAPE, \n",
    "                                 lr=hparams_per_fold[inner_fold[\"inner_fold\"]][\"lr\"], \n",
    "                                 gamma=hparams_per_fold[inner_fold[\"inner_fold\"]][\"gamma\"], \n",
    "                                 alpha=hparams_per_fold[inner_fold[\"inner_fold\"]][\"alpha\"])\n",
    "\n",
    "        model.fit(\n",
    "            inner_fold[\"train_ds\"],\n",
    "            epochs = EPOCHS_PER_FOLD,\n",
    "            validation_data=inner_fold[\"val_ds\"],\n",
    "            steps_per_epoch=STEPS_PER_TRAINING_EPOCH,\n",
    "            validation_steps = STEPS_PER_VALIDATION_EPOCH,\n",
    "            verbose=1,\n",
    "            callbacks=[early, ckpt]\n",
    "        )\n",
    "        \n",
    "        vals = model.evaluate(inner_fold[\"test_ds\"], verbose=0)\n",
    "        print(model.metrics_names)\n",
    "        print(vals)\n",
    "        inner_scores.append(vals[2])\n",
    "    \n",
    "    mean_test_acc = np.mean(inner_scores)\n",
    "    print(f\"Inner CV mean test acc: {mean_test_acc:.3f}\")\n",
    "    \n",
    "    # Retrain with the best parameters\n",
    "    best_inner = np.argmax(inner_scores)\n",
    "    \n",
    "    model = build_binary_cnn(input_shape=INPUT_SHAPE, \n",
    "                                lr=hparams_per_fold[best_inner][\"lr\"], \n",
    "                                gamma=hparams_per_fold[best_inner][\"gamma\"], \n",
    "                                alpha=hparams_per_fold[best_inner][\"alpha\"])\n",
    "    model.fit(\n",
    "        outer_fold[\"train_ds\"],\n",
    "        epochs = EPOCHS_PER_FOLD,\n",
    "        steps_per_epoch=STEPS_PER_TRAINING_EPOCH,\n",
    "        validation_steps = STEPS_PER_VALIDATION_EPOCH,\n",
    "        verbose=1,\n",
    "        callbacks=[early, ckpt]\n",
    "    )\n",
    "    \n",
    "    vals = model.evaluate(outer_fold[\"test_ds\"], verbose=0)\n",
    "    per_fold_results.append(vals[2])\n",
    "\n",
    "print(per_fold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bef1e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - Brier score: 0.2424 - acc: 0.5781 - auc: 0.6417 - auprc: 0.4242 - loss: 0.4188 - precision: 0.4211 - recall: 0.7619\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - Brier score: 0.2620 - acc: 0.5938 - auc: 0.5172 - auprc: 0.3610 - loss: 0.5261 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - Brier score: 0.2539 - acc: 0.6094 - auc: 0.3793 - auprc: 0.2667 - loss: 0.4524 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 204ms/step - Brier score: 0.2440 - acc: 0.6000 - auc: 0.5248 - auprc: 0.3871 - loss: 0.4013 - precision: 0.3889 - recall: 0.4375\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - Brier score: 0.2277 - acc: 0.6250 - auc: 0.5835 - auprc: 0.3817 - loss: 0.3708 - precision: 0.4000 - recall: 0.4000\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - Brier score: 0.2372 - acc: 0.6719 - auc: 0.5959 - auprc: 0.4766 - loss: 0.3975 - precision: 0.7000 - recall: 0.2800\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - Brier score: 0.1926 - acc: 0.7400 - auc: 0.6382 - auprc: 0.3113 - loss: 0.3132 - precision: 0.3333 - recall: 0.0833\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - Brier score: 0.2092 - acc: 0.6719 - auc: 0.6489 - auprc: 0.4937 - loss: 0.3446 - precision: 0.5000 - recall: 0.1429\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - Brier score: 0.2231 - acc: 0.6094 - auc: 0.6339 - auprc: 0.5290 - loss: 0.3694 - precision: 0.4000 - recall: 0.0833       \n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - Brier score: 0.2279 - acc: 0.6250 - auc: 0.5179 - auprc: 0.3250 - loss: 0.3724 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - Brier score: 0.2261 - acc: 0.6400 - auc: 0.5882 - auprc: 0.3421 - loss: 0.3648 - precision: 0.3333 - recall: 0.1250\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Brier score: 0.2134 - acc: 0.7031 - auc: 0.5818 - auprc: 0.4671 - loss: 0.3598 - precision: 0.5714 - recall: 0.2000\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - Brier score: 0.2221 - acc: 0.6562 - auc: 0.6503 - auprc: 0.5761 - loss: 0.3661 - precision: 0.7143 - recall: 0.2000\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - Brier score: 0.1875 - acc: 0.7800 - auc: 0.7193 - auprc: 0.5384 - loss: 0.2996 - precision: 1.0000 - recall: 0.0833\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - Brier score: 0.2205 - acc: 0.7031 - auc: 0.5604 - auprc: 0.4917 - loss: 0.3639 - precision: 0.6667 - recall: 0.1905\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - Brier score: 0.2123 - acc: 0.6250 - auc: 0.6953 - auprc: 0.5455 - loss: 0.3460 - precision: 0.5000 - recall: 0.1667\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - Brier score: 0.2297 - acc: 0.6406 - auc: 0.5162 - auprc: 0.3504 - loss: 0.3740 - precision: 0.4000 - recall: 0.0909\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - Brier score: 0.2073 - acc: 0.6400 - auc: 0.7105 - auprc: 0.4831 - loss: 0.3318 - precision: 0.3333 - recall: 0.1250       \n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - Brier score: 0.2163 - acc: 0.7031 - auc: 0.6182 - auprc: 0.4046 - loss: 0.3517 - precision: 0.5455 - recall: 0.3000\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - Brier score: 0.2149 - acc: 0.6250 - auc: 0.6923 - auprc: 0.5601 - loss: 0.3508 - precision: 0.5714 - recall: 0.1600\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - Brier score: 0.1990 - acc: 0.7400 - auc: 0.5636 - auprc: 0.2862 - loss: 0.3219 - precision: 0.3333 - recall: 0.0833       \n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - Brier score: 0.2210 - acc: 0.6719 - auc: 0.5731 - auprc: 0.3938 - loss: 0.3584 - precision: 0.5000 - recall: 0.1429\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - Brier score: 0.2124 - acc: 0.6406 - auc: 0.6958 - auprc: 0.5955 - loss: 0.3437 - precision: 0.5556 - recall: 0.2083\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - Brier score: 0.2135 - acc: 0.6719 - auc: 0.6434 - auprc: 0.5304 - loss: 0.3448 - precision: 0.5556 - recall: 0.2273\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - Brier score: 0.1999 - acc: 0.6600 - auc: 0.7436 - auprc: 0.5052 - loss: 0.3199 - precision: 0.4000 - recall: 0.1250\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - Brier score: 0.1902 - acc: 0.7344 - auc: 0.7506 - auprc: 0.5830 - loss: 0.3096 - precision: 0.7143 - recall: 0.2500\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - Brier score: 0.2064 - acc: 0.6875 - auc: 0.7164 - auprc: 0.6770 - loss: 0.3431 - precision: 0.7778 - recall: 0.2800\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - Brier score: 0.1884 - acc: 0.7400 - auc: 0.7237 - auprc: 0.3735 - loss: 0.3045 - precision: 0.3333 - recall: 0.0833       \n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - Brier score: 0.2028 - acc: 0.6250 - auc: 0.7082 - auprc: 0.5055 - loss: 0.3287 - precision: 0.3846 - recall: 0.2381\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - Brier score: 0.1799 - acc: 0.7812 - auc: 0.8365 - auprc: 0.8238 - loss: 0.2982 - precision: 0.8571 - recall: 0.5000\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - Brier score: 0.2048 - acc: 0.6875 - auc: 0.6775 - auprc: 0.5836 - loss: 0.3343 - precision: 0.6250 - recall: 0.2273\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - Brier score: 0.2006 - acc: 0.7200 - auc: 0.7252 - auprc: 0.5167 - loss: 0.3247 - precision: 0.6667 - recall: 0.2500\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - Brier score: 0.1874 - acc: 0.7656 - auc: 0.7528 - auprc: 0.5913 - loss: 0.3080 - precision: 0.7778 - recall: 0.3500\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - Brier score: 0.1742 - acc: 0.7500 - auc: 0.8379 - auprc: 0.7841 - loss: 0.2912 - precision: 0.8462 - recall: 0.4400\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - Brier score: 0.1612 - acc: 0.8400 - auc: 0.8673 - auprc: 0.7347 - loss: 0.2599 - precision: 0.8333 - recall: 0.4167\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - Brier score: 0.1985 - acc: 0.6562 - auc: 0.7519 - auprc: 0.4839 - loss: 0.3264 - precision: 0.4615 - recall: 0.2857\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - Brier score: 0.1541 - acc: 0.8438 - auc: 0.9057 - auprc: 0.8864 - loss: 0.2531 - precision: 1.0000 - recall: 0.5833\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - Brier score: 0.1885 - acc: 0.7344 - auc: 0.7440 - auprc: 0.6852 - loss: 0.3192 - precision: 0.6667 - recall: 0.4545\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - Brier score: 0.1825 - acc: 0.7200 - auc: 0.7812 - auprc: 0.5986 - loss: 0.3060 - precision: 0.6000 - recall: 0.3750\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - Brier score: 0.1477 - acc: 0.7812 - auc: 0.8960 - auprc: 0.7940 - loss: 0.2450 - precision: 0.7500 - recall: 0.4500\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - Brier score: 0.1753 - acc: 0.7812 - auc: 0.8205 - auprc: 0.8153 - loss: 0.2974 - precision: 0.9231 - recall: 0.4800\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - Brier score: 0.1547 - acc: 0.8800 - auc: 0.8366 - auprc: 0.7380 - loss: 0.2529 - precision: 0.8750 - recall: 0.5833\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - Brier score: 0.1829 - acc: 0.7500 - auc: 0.7724 - auprc: 0.6050 - loss: 0.3053 - precision: 0.6667 - recall: 0.4762\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - Brier score: 0.1314 - acc: 0.8906 - auc: 0.9354 - auprc: 0.9228 - loss: 0.2200 - precision: 0.9474 - recall: 0.7500\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - Brier score: 0.1803 - acc: 0.7500 - auc: 0.7787 - auprc: 0.7177 - loss: 0.3018 - precision: 0.6875 - recall: 0.5000\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - Brier score: 0.1771 - acc: 0.6800 - auc: 0.7812 - auprc: 0.6209 - loss: 0.2955 - precision: 0.5000 - recall: 0.3125\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - Brier score: 0.1277 - acc: 0.9062 - auc: 0.9341 - auprc: 0.8980 - loss: 0.2150 - precision: 0.8500 - recall: 0.8500\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - Brier score: 0.1484 - acc: 0.7812 - auc: 0.8662 - auprc: 0.8432 - loss: 0.2540 - precision: 0.7895 - recall: 0.6000\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - Brier score: 0.1255 - acc: 0.8800 - auc: 0.9408 - auprc: 0.7928 - loss: 0.2112 - precision: 0.7500 - recall: 0.7500\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - Brier score: 0.1692 - acc: 0.7656 - auc: 0.7835 - auprc: 0.7208 - loss: 0.3012 - precision: 0.7500 - recall: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x782c287c4f20>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can train the actual model we use for the soundscapes based on the best configuration\n",
    "\n",
    "model = build_binary_cnn(input_shape=INPUT_SHAPE, \n",
    "                         lr=hparams_per_fold[best_inner][\"lr\"], \n",
    "                         gamma=hparams_per_fold[best_inner][\"gamma\"], \n",
    "                         alpha=hparams_per_fold[best_inner][\"alpha\"])\n",
    "model.fit(\n",
    "    datasets[np.argmax(per_fold_results)][\"train_ds\"],\n",
    "    epochs = EPOCHS_PER_FOLD,\n",
    "    steps_per_epoch=STEPS_PER_TRAINING_EPOCH,\n",
    "    callbacks=[early, ckpt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc678cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "SOUNDSCAPE_DIR = \"datasets/birdclef_2021/train_soundscapes\"\n",
    "\n",
    "# Load the labels\n",
    "soundscape_labels = pd.read_csv(\"datasets/birdclef_2021/train_soundscape_labels.csv\")\n",
    "\n",
    "EXP_NAME = \"mixup\"\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "EXP_DIR = os.path.join(OUTPUT_DIR, EXP_NAME)\n",
    "\n",
    "# Output folders\n",
    "CM_DIR = os.path.join(EXP_DIR, \"confusion_matrices\")\n",
    "METRICS_DIR = os.path.join(EXP_DIR, \"metrics\")\n",
    "SCAN_DIR = os.path.join(EXP_DIR, \"threshold_scans\")\n",
    "os.makedirs(EXP_DIR, exist_ok=True)\n",
    "os.makedirs(CM_DIR, exist_ok=True)\n",
    "os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "os.makedirs(SCAN_DIR, exist_ok=True)\n",
    "\n",
    "soundscapes = []\n",
    "def process_soundscape(path: str):\n",
    "    # Load the soundscape\n",
    "    y, _ = librosa.load(os.path.join(SOUNDSCAPE_DIR, path), sr=SAMPLE_RATE)\n",
    "\n",
    "    # Filter for the current file\n",
    "    site = path.split(\"_\")[1]\n",
    "    audio_id = int(path.split(\"_\")[0])\n",
    "\n",
    "    # Pass it through a bandpass\n",
    "    b, a = signal.butter(4, [200, 7999], fs=SAMPLE_RATE, btype='band')\n",
    "    y = signal.lfilter(b, a, y)\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, math.ceil(len(y)/BYTES_PER_SECOND)):\n",
    "        # Cut it into chunks of BYTES_PER_SECOND\n",
    "        chunk = y[i*BYTES_PER_SECOND:(i+1)*BYTES_PER_SECOND]\n",
    "        \n",
    "        # Convert to spectrogram\n",
    "        spec = generate_mel_spectrogram(chunk)\n",
    "        chunks.append(spec)\n",
    "        \n",
    "    labels = soundscape_labels[(soundscape_labels[\"site\"] == site) & (soundscape_labels[\"audio_id\"] == audio_id)].copy()\n",
    "    labels[\"class\"] = labels[\"birds\"].apply(lambda x: \"target\" if TARGET in x else \"other\")\n",
    "    \n",
    "    # Predict the labels with the model\n",
    "    predictions = model.predict(np.array(chunks), verbose=0)\n",
    "    labels[\"predictions\"] = predictions\n",
    "    \n",
    "    soundscapes.append({\n",
    "        \"site\":site,\n",
    "        \"audio_id\":audio_id,\n",
    "        \"labels\":labels\n",
    "    })\n",
    "    \n",
    "    # Also export the DF\n",
    "    labels.to_csv(os.path.join(EXP_DIR, f\"{site}_{audio_id}.csv\"))\n",
    "    \n",
    "    # Clean up\n",
    "    del y, chunks\n",
    "\n",
    "for f in os.listdir(SOUNDSCAPE_DIR):\n",
    "    process_soundscape(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d2d4f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SSW_2782] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_7843] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[COR_7954] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[COR_31928] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_42907] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_28933] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[COR_50878] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_10534] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[COR_57610] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_26709] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_20152] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[COR_26746] Best (target-f1) threshold: 0.17 | P=0.207 R=0.783 F1=0.327\n",
      "[COR_44957] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_14473] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[COR_7019] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[COR_11254] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_51010] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[SSW_54955] Best (target-f1) threshold: 0.01 | P=0.000 R=0.000 F1=0.000\n",
      "[COR_21767] Best (target-f1) threshold: 0.01 | P=0.533 R=1.000 F1=0.696\n",
      "[COR_18003] Best (target-f1) threshold: 0.01 | P=0.767 R=1.000 F1=0.868\n",
      "[GLOBAL] Using threshold 0.01 optimized for target F1\n"
     ]
    }
   ],
   "source": [
    "# Results processing and comparison\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Ensure output dirs exist (adjust paths if you defined them earlier)\n",
    "CM_DIR = os.path.join(EXP_DIR, \"confusion_matrices\")\n",
    "METRICS_DIR = os.path.join(EXP_DIR, \"metrics\")\n",
    "SCAN_DIR = os.path.join(EXP_DIR, \"threshold_scans\")\n",
    "os.makedirs(CM_DIR, exist_ok=True)\n",
    "os.makedirs(METRICS_DIR, exist_ok=True)\n",
    "os.makedirs(SCAN_DIR, exist_ok=True)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels=None, class_names=None,\n",
    "                          normalize=False, cmap=\"Blues\"):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix with fixed shape using all known labels.\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    if class_names is None:\n",
    "        class_names = [str(l) for l in labels]\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(np.float32) / cm.sum(axis=1, keepdims=True)\n",
    "        cm = np.nan_to_num(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.ax.set_ylabel(\"Counts\" if not normalize else \"Proportion\", rotation=-90, va=\"bottom\")\n",
    "\n",
    "    ax.set(\n",
    "        xticks=np.arange(len(labels)),\n",
    "        yticks=np.arange(len(labels)),\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        ylabel=\"True label\",\n",
    "        xlabel=\"Predicted label\"\n",
    "    )\n",
    "    plt.setp(ax.get_xticklabels(), rotation=0)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0 if cm.size else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def find_threshold_macroF1(df: pd.DataFrame, step=0.01, eps=1e-3):\n",
    "    label_col = \"label\" if \"label\" in df.columns else \"class\"\n",
    "    y_true_str = df[label_col].values\n",
    "    y_prob = df[\"predictions\"].astype(float).values\n",
    "    labels = [\"target\",\"other\"]\n",
    "\n",
    "    thresholds = np.arange(eps, 1.0 + 1e-9, step)\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        y_pred_str = np.where(y_prob >= t, \"target\", \"other\")\n",
    "        cm = confusion_matrix(y_true_str, y_pred_str, labels=labels)\n",
    "        # F1 for 'target'\n",
    "        tp_t, fp_t, fn_t = int(cm[0,0]), int(cm[1,0]), int(cm[0,1])\n",
    "        p_t = tp_t / (tp_t + fp_t) if (tp_t + fp_t) else 0.0\n",
    "        r_t = tp_t / (tp_t + fn_t) if (tp_t + fn_t) else 0.0\n",
    "        f1_t = 2*p_t*r_t/(p_t+r_t) if (p_t+r_t) else 0.0\n",
    "        # F1 for 'other' (as positive)\n",
    "        tp_o, fp_o, fn_o = int(cm[1,1]), int(cm[0,1]), int(cm[1,0])\n",
    "        p_o = tp_o / (tp_o + fp_o) if (tp_o + fp_o) else 0.0\n",
    "        r_o = tp_o / (tp_o + fn_o) if (tp_o + fn_o) else 0.0\n",
    "        f1_o = 2*p_o*r_o/(p_o+r_o) if (p_o+r_o) else 0.0\n",
    "        rows.append({\"threshold\": t, \"f1_macro\": (f1_t + f1_o)/2.0})\n",
    "\n",
    "    dfm = pd.DataFrame(rows)\n",
    "    best_row = dfm.iloc[dfm[\"f1_macro\"].values.argmax()]\n",
    "    return float(best_row[\"threshold\"]), dfm\n",
    "\n",
    "def save_current_fig(fig, path_png, path_svg=None, dpi=200):\n",
    "    fig.savefig(path_png, dpi=dpi, bbox_inches=\"tight\")\n",
    "    if path_svg:\n",
    "        fig.savefig(path_svg, bbox_inches=\"tight\")\n",
    "\n",
    "# Safe division P/R/F1 helper (inline, no external deps)\n",
    "def _prf(tp, fp, fn):\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1   = (2 * prec * rec) / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "    return prec, rec, f1\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# choose which TARGET metric to optimize: \"f1\" | \"precision\" | \"recall\"\n",
    "TARGET_OPTIMIZE = \"f1\"\n",
    "\n",
    "for rslt in soundscapes:\n",
    "    df = rslt[\"labels\"]\n",
    "\n",
    "    base = f\"{rslt['site']}_{rslt['audio_id']}\"\n",
    "\n",
    "    # ---- Optimize threshold for the TARGET class on THIS file ----\n",
    "    y_true_bin = (df[\"class\"].values == \"target\").astype(int)\n",
    "    y_prob = df[\"predictions\"].astype(float).values\n",
    "\n",
    "    thresholds = np.arange(0.01, 1.0 + 1e-9, 0.01)  # exclude 0.0 to prevent degenerate all-target\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        y_pred_bin = (y_prob >= t).astype(int)\n",
    "        prec = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "        rec  = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "        f1   = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "        rows.append({\"threshold\": float(t), \"precision\": prec, \"recall\": rec, \"f1\": f1})\n",
    "\n",
    "    table = pd.DataFrame(rows)\n",
    "    best_idx = table[TARGET_OPTIMIZE].values.argmax()\n",
    "    best_row = table.iloc[best_idx]\n",
    "    best_thr = float(best_row[\"threshold\"])\n",
    "    best_metrics = {\"precision\": float(best_row[\"precision\"]),\n",
    "                    \"recall\": float(best_row[\"recall\"]),\n",
    "                    \"f1\": float(best_row[\"f1\"])}\n",
    "\n",
    "    print(f\"[{base}] Best (target-{TARGET_OPTIMIZE}) threshold: {best_thr:.2f} | \"\n",
    "          f\"P={best_metrics['precision']:.3f} R={best_metrics['recall']:.3f} F1={best_metrics['f1']:.3f}\")\n",
    "\n",
    "    # Save the per-file threshold scan (optional but handy to inspect)\n",
    "    table.to_csv(os.path.join(SCAN_DIR, f\"{base}_threshold_scan.csv\"), index=False)\n",
    "\n",
    "    # Apply best threshold to produce hard labels\n",
    "    df[\"predicted_class\"] = np.where(df[\"predictions\"] >= best_thr, \"target\", \"other\")\n",
    "\n",
    "    # Fixed label order\n",
    "    labels_fixed = [\"target\", \"other\"]\n",
    "\n",
    "    # Confusion matrix and save plot\n",
    "    cm = confusion_matrix(df[\"class\"], df[\"predicted_class\"], labels=labels_fixed)\n",
    "    ax = plot_confusion_matrix(df[\"class\"], df[\"predicted_class\"], labels=labels_fixed, class_names=labels_fixed)\n",
    "    fig = ax.figure\n",
    "    save_current_fig(\n",
    "        fig,\n",
    "        os.path.join(CM_DIR, f\"{base}_cm.png\"),\n",
    "        path_svg=os.path.join(CM_DIR, f\"{base}_cm.svg\"),\n",
    "        dpi=220\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "    # --- Single consolidated metrics CSV per soundscape (per-class + global) ---\n",
    "    # CM layout: rows true [target, other], cols pred [target, other]\n",
    "    tp_t, fp_t, fn_t, tn_t = int(cm[0, 0]), int(cm[1, 0]), int(cm[0, 1]), int(cm[1, 1])  # positive='target'\n",
    "    tp_o, fp_o, fn_o, tn_o = int(cm[1, 1]), int(cm[0, 1]), int(cm[1, 0]), int(cm[0, 0])  # positive='other'\n",
    "\n",
    "    support_t = int((df[\"class\"].values == \"target\").sum())\n",
    "    support_o = int((df[\"class\"].values == \"other\").sum())\n",
    "    total = support_t + support_o\n",
    "\n",
    "    p_t = tp_t / (tp_t + fp_t) if (tp_t + fp_t) > 0 else 0.0\n",
    "    r_t = tp_t / (tp_t + fn_t) if (tp_t + fn_t) > 0 else 0.0\n",
    "    f1_t = (2 * p_t * r_t) / (p_t + r_t) if (p_t + r_t) > 0 else 0.0\n",
    "\n",
    "    p_o = tp_o / (tp_o + fp_o) if (tp_o + fp_o) > 0 else 0.0\n",
    "    r_o = tp_o / (tp_o + fn_o) if (tp_o + fn_o) > 0 else 0.0\n",
    "    f1_o = (2 * p_o * r_o) / (p_o + r_o) if (p_o + r_o) > 0 else 0.0\n",
    "\n",
    "    acc = (tp_t + tn_t) / max(total, 1)\n",
    "\n",
    "    micro_p = precision_score(y_true_bin, (df[\"predicted_class\"].values == \"target\").astype(int), zero_division=0)\n",
    "    micro_r = recall_score(y_true_bin, (df[\"predicted_class\"].values == \"target\").astype(int), zero_division=0)\n",
    "    micro_f1 = f1_score(y_true_bin, (df[\"predicted_class\"].values == \"target\").astype(int), zero_division=0)\n",
    "\n",
    "    macro_p = (p_t + p_o) / 2.0\n",
    "    macro_r = (r_t + r_o) / 2.0\n",
    "    macro_f1 = (f1_t + f1_o) / 2.0\n",
    "\n",
    "    metrics_rows = [\n",
    "        {\n",
    "            \"site\": rslt[\"site\"], \"audio_id\": rslt[\"audio_id\"], \"class\": \"target\",\n",
    "            \"threshold\": best_thr, \"support\": support_t,\n",
    "            \"tp\": tp_t, \"fp\": fp_t, \"fn\": fn_t, \"tn\": tn_t,\n",
    "            \"precision\": p_t, \"recall\": r_t, \"f1\": f1_t, \"accuracy\": acc\n",
    "        },\n",
    "        {\n",
    "            \"site\": rslt[\"site\"], \"audio_id\": rslt[\"audio_id\"], \"class\": \"other\",\n",
    "            \"threshold\": best_thr, \"support\": support_o,\n",
    "            \"tp\": tp_o, \"fp\": fp_o, \"fn\": fn_o, \"tn\": tn_o,\n",
    "            \"precision\": p_o, \"recall\": r_o, \"f1\": f1_o, \"accuracy\": acc\n",
    "        },\n",
    "        {\n",
    "            \"site\": rslt[\"site\"], \"audio_id\": rslt[\"audio_id\"], \"class\": \"global\",\n",
    "            \"threshold\": best_thr, \"support\": total,\n",
    "            \"tp\": tp_t + tp_o, \"fp\": fp_t + fp_o, \"fn\": fn_t + fn_o, \"tn\": tn_t + tn_o,\n",
    "            \"precision_macro\": macro_p, \"recall_macro\": macro_r, \"f1_macro\": macro_f1,\n",
    "            \"precision_micro\": micro_p, \"recall_micro\": micro_r, \"f1_micro\": micro_f1,\n",
    "            \"accuracy\": acc\n",
    "        },\n",
    "    ]\n",
    "    pd.DataFrame(metrics_rows).to_csv(os.path.join(METRICS_DIR, f\"{base}_metrics.csv\"), index=False)\n",
    "\n",
    "    # Optional: text report\n",
    "    report_txt = classification_report(df[\"class\"], df[\"predicted_class\"], labels=labels_fixed, zero_division=0)\n",
    "    with open(os.path.join(METRICS_DIR, f\"{base}_classification_report.txt\"), \"w\") as f:\n",
    "        f.write(f\"Best threshold (target-{TARGET_OPTIMIZE}): {best_thr:.4f}\\n\\n\")\n",
    "        f.write(report_txt)\n",
    "\n",
    "    # Accumulate for global summary if you still need it later\n",
    "    all_rows.append(df[[\"class\", \"predictions\"]].assign(site=rslt[\"site\"], audio_id=rslt[\"audio_id\"]))\n",
    "\n",
    "# ------- Global summary across all soundscapes (optimize TARGET metrics) -------\n",
    "if all_rows:\n",
    "    # Build a single DataFrame across all soundscapes with site/audio_id attached\n",
    "    df_all = pd.concat(\n",
    "        [s[\"labels\"].assign(site=s[\"site\"], audio_id=s[\"audio_id\"]) for s in soundscapes],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Ground-truth column can be 'class' (recommended) or 'label'\n",
    "    gt_col = \"class\" if \"class\" in df_all.columns else \"label\"\n",
    "    assert gt_col in df_all.columns and \"predictions\" in df_all.columns, \\\n",
    "        \"Expected columns for ground truth ('class' or 'label') and 'predictions'.\"\n",
    "\n",
    "    # -------- Optimize global threshold for TARGET-class metric --------\n",
    "    # Only use files that contain at least one 'target' to PICK the threshold\n",
    "    files_with_pos = (\n",
    "        df_all.groupby([\"site\", \"audio_id\"])[gt_col]\n",
    "        .apply(lambda s: (s == \"target\").any())\n",
    "    )\n",
    "    pos_file_index = files_with_pos[files_with_pos].index\n",
    "    mask_with_pos = df_all.set_index([\"site\", \"audio_id\"]).index.isin(pos_file_index)\n",
    "    df_for_thr = df_all[mask_with_pos].reset_index(drop=True)\n",
    "\n",
    "    # Choose which target metric to optimize: 'f1' | 'precision' | 'recall'\n",
    "    TARGET_OPTIMIZE = \"f1\"\n",
    "\n",
    "    if len(df_for_thr) > 0:\n",
    "        y_true = (df_for_thr[gt_col].values == \"target\").astype(int)\n",
    "        y_prob = df_for_thr[\"predictions\"].astype(float).values\n",
    "\n",
    "        thresholds = np.arange(0.01, 1.0 + 1e-9, 0.01)  # exclude 0 to avoid \"all-target\" degenerate choice\n",
    "        best_thr, best_val = 0.5, -1.0\n",
    "\n",
    "        for t in thresholds:\n",
    "            y_pred = (y_prob >= t).astype(int)\n",
    "            if TARGET_OPTIMIZE == \"precision\":\n",
    "                val = precision_score(y_true, y_pred, zero_division=0)\n",
    "            elif TARGET_OPTIMIZE == \"recall\":\n",
    "                val = recall_score(y_true, y_pred, zero_division=0)\n",
    "            else:  # \"f1\"\n",
    "                val = f1_score(y_true, y_pred, zero_division=0)\n",
    "            if val > best_val:\n",
    "                best_val, best_thr = val, float(t)\n",
    "        g_thr = best_thr\n",
    "    else:\n",
    "        g_thr = 0.5  # fallback if no positives anywhere\n",
    "    print(f\"[GLOBAL] Using threshold {g_thr:.2f} optimized for target {TARGET_OPTIMIZE.upper()}\")\n",
    "\n",
    "    # ---- Apply global threshold to ALL rows (including files with no target) ----\n",
    "    y_true_all = df_all[gt_col].values\n",
    "    y_pred_all = np.where(df_all[\"predictions\"].values >= g_thr, \"target\", \"other\")\n",
    "    labels_fixed = [\"target\", \"other\"]\n",
    "\n",
    "    # Plot/save global CM\n",
    "    cm_all = confusion_matrix(y_true_all, y_pred_all, labels=labels_fixed)\n",
    "    ax = plot_confusion_matrix(y_true_all, y_pred_all, labels=labels_fixed, class_names=labels_fixed)\n",
    "    fig = ax.figure\n",
    "    save_current_fig(\n",
    "        fig,\n",
    "        os.path.join(CM_DIR, \"GLOBAL_cm.png\"),\n",
    "        path_svg=os.path.join(CM_DIR, \"GLOBAL_cm.svg\"),\n",
    "        dpi=220\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Components (rows true [target, other], cols pred [target, other])\n",
    "    tp_t, fp_t, fn_t, tn_t = int(cm_all[0, 0]), int(cm_all[1, 0]), int(cm_all[0, 1]), int(cm_all[1, 1])\n",
    "    tp_o, fp_o, fn_o, tn_o = int(cm_all[1, 1]), int(cm_all[0, 1]), int(cm_all[1, 0]), int(cm_all[0, 0])\n",
    "\n",
    "    support_t = int((y_true_all == \"target\").sum())\n",
    "    support_o = int((y_true_all == \"other\").sum())\n",
    "    total = support_t + support_o\n",
    "\n",
    "    def _prf(tp, fp, fn):\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1   = (2 * prec * rec) / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "        return prec, rec, f1\n",
    "\n",
    "    p_t, r_t, f1_t = _prf(tp_t, fp_t, fn_t)\n",
    "    p_o, r_o, f1_o = _prf(tp_o, fp_o, fn_o)\n",
    "\n",
    "    acc = (tp_t + tn_t) / max(total, 1)\n",
    "\n",
    "    # Micro and macro (binary)\n",
    "    y_true_bin = (y_true_all == \"target\").astype(int)\n",
    "    y_pred_bin = (y_pred_all == \"target\").astype(int)\n",
    "    micro_p = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "    micro_r = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "    micro_f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "\n",
    "    macro_p = (p_t + p_o) / 2.0\n",
    "    macro_r = (r_t + r_o) / 2.0\n",
    "    macro_f1 = (f1_t + f1_o) / 2.0\n",
    "\n",
    "    # Save a single GLOBAL metrics CSV with per-class + global rows\n",
    "    global_rows = [\n",
    "        {\n",
    "            \"site\": \"GLOBAL\", \"audio_id\": -1, \"class\": \"target\",\n",
    "            \"threshold\": g_thr, \"support\": support_t,\n",
    "            \"tp\": tp_t, \"fp\": fp_t, \"fn\": fn_t, \"tn\": tn_t,\n",
    "            \"precision\": p_t, \"recall\": r_t, \"f1\": f1_t, \"accuracy\": acc\n",
    "        },\n",
    "        {\n",
    "            \"site\": \"GLOBAL\", \"audio_id\": -1, \"class\": \"other\",\n",
    "            \"threshold\": g_thr, \"support\": support_o,\n",
    "            \"tp\": tp_o, \"fp\": fp_o, \"fn\": fn_o, \"tn\": tn_o,\n",
    "            \"precision\": p_o, \"recall\": r_o, \"f1\": f1_o, \"accuracy\": acc\n",
    "        },\n",
    "        {\n",
    "            \"site\": \"GLOBAL\", \"audio_id\": -1, \"class\": \"global\",\n",
    "            \"threshold\": g_thr, \"support\": total,\n",
    "            \"tp\": tp_t + tp_o, \"fp\": fp_t + fp_o, \"fn\": fn_t + fn_o, \"tn\": tn_t + tn_o,\n",
    "            \"precision_macro\": macro_p, \"recall_macro\": macro_r, \"f1_macro\": macro_f1,\n",
    "            \"precision_micro\": micro_p, \"recall_micro\": micro_r, \"f1_micro\": micro_f1,\n",
    "            \"accuracy\": acc\n",
    "        },\n",
    "    ]\n",
    "    pd.DataFrame(global_rows).to_csv(os.path.join(METRICS_DIR, \"GLOBAL_metrics.csv\"), index=False)\n",
    "\n",
    "    with open(os.path.join(METRICS_DIR, \"GLOBAL_classification_report.txt\"), \"w\") as f:\n",
    "        f.write(f\"Best threshold (target-{TARGET_OPTIMIZE}): {g_thr:.4f}\\n\\n\")\n",
    "        f.write(classification_report(y_true_all, y_pred_all, labels=labels_fixed, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
